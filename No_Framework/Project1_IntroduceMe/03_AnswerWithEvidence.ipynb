{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f68baa",
   "metadata": {},
   "source": [
    "# Answer-with-Evidence Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7d1f3",
   "metadata": {},
   "source": [
    "Core Tool Design Patterns (No Memory)\n",
    "\n",
    "1. Deterministic Tool Pattern\n",
    "\n",
    "Purpose: Fetch or compute facts\n",
    "Properties:\n",
    "\n",
    "No LLM\n",
    "\n",
    "Predictable output\n",
    "\n",
    "External or internal logic\n",
    "\n",
    "Examples:\n",
    "\n",
    "Search\n",
    "\n",
    "Math\n",
    "\n",
    "Parsing\n",
    "\n",
    "Validation via rules\n",
    "\n",
    "2. Interpretation Tool Pattern\n",
    "\n",
    "Purpose: Convert raw data into meaning\n",
    "Properties:\n",
    "\n",
    "LLM-based\n",
    "\n",
    "No external calls\n",
    "\n",
    "Input constrained\n",
    "\n",
    "Examples:\n",
    "\n",
    "Summarize\n",
    "\n",
    "Extract entities\n",
    "\n",
    "Classify\n",
    "\n",
    "Normalize text\n",
    "\n",
    "3. Evaluation Tool Pattern\n",
    "\n",
    "Purpose: Judge quality against criteria\n",
    "Properties:\n",
    "\n",
    "LLM-based\n",
    "\n",
    "Structured output\n",
    "\n",
    "Conservative bias\n",
    "\n",
    "Examples:\n",
    "\n",
    "Relevance check\n",
    "\n",
    "Completeness check\n",
    "\n",
    "Risk detection\n",
    "\n",
    "4. Orchestration Pattern (Non-agentic)\n",
    "\n",
    "Purpose: Decide what runs next\n",
    "Properties:\n",
    "\n",
    "Plain Python\n",
    "\n",
    "No reasoning\n",
    "\n",
    "Explicit control flow\n",
    "\n",
    "5. Repair / Fallback Pattern\n",
    "\n",
    "Purpose: Improve or recover from failure\n",
    "Properties:\n",
    "\n",
    "Conditional\n",
    "\n",
    "Targeted\n",
    "\n",
    "Limited retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0157bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "813be20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde8b7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cefb8t\\AppData\\Local\\Temp\\ipykernel_9844\\793068002.py:1: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai1\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7229630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai1.GenerativeModel('gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0173c97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Key in memory: AIzaS...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(f\"Current Key in memory: {key[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17baf04",
   "metadata": {},
   "source": [
    "Deterministic: Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a832f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e9ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa6b107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035a90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "\n",
    "\n",
    "def normalize_serpapi_results(results: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Pattern: Deterministic normalization of SerpAPI search results.\n",
    "\n",
    "    Produces source descriptors ONLY.\n",
    "    Does NOT fetch pages.\n",
    "    Does NOT create segments.\n",
    "    \"\"\"\n",
    "\n",
    "    normalized = []\n",
    "\n",
    "    for r in results:\n",
    "        title = r.get(\"title\", \"\").strip()\n",
    "        date = r.get(\"date\", \"\").strip()\n",
    "\n",
    "        source_id = slugify(f\"{title}_{date}\") if title else None\n",
    "\n",
    "        normalized.append({\n",
    "            \"source_id\": source_id,\n",
    "            \"title\": title,\n",
    "            \"url\": r.get(\"link\"),\n",
    "            \"published_date\": date,\n",
    "            \"provider\": \"serpapi\"\n",
    "        })\n",
    "\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9262eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from datetime import datetime\n",
    "\n",
    "def get_search_results(query: str):\n",
    "    \"\"\"\n",
    "    Searches for the latest information using DuckDuckGo (Free/No Key).\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    # 'd' mimics SerpAPI's 'qdr:d' (last 24 hours)\n",
    "    num_results = 5 \n",
    "\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            # Using text search for general queries\n",
    "            results = ddgs.text(\n",
    "                query, \n",
    "                region='us-en', \n",
    "                safesearch='moderate', \n",
    "                timelimit='d', \n",
    "                max_results=num_results\n",
    "            )\n",
    "            blocked_domains = {\"bing.com\", \"doubleclick.net\"}\n",
    "\n",
    "            for r in results:\n",
    "                # Generate a unique source_id (domain_year)\n",
    "                domain = r['href'].split('//')[-1].split('/')[0].replace('www.', '')\n",
    "                source_id = f\"{domain.split('.')[0]}_{datetime.now().year}\"\n",
    "                # print(domain)\n",
    "                if domain in blocked_domains:\n",
    "                    continue\n",
    "                \n",
    "                # Normalize to your requested output format\n",
    "                final_results.append({\n",
    "                    \"source_id\": source_id,\n",
    "                    \"title\": r['title'],\n",
    "                    \"url\": r['href'],\n",
    "                    \"published_date\": \"Recent (Last 24h)\",\n",
    "                    \"retrieved_from\": \"duckduckgo\"\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Return empty list to avoid breaking the LLM tool-calling chain\n",
    "        return [{\"error\": f\"DuckDuckGo search failed: {str(e)}\"}]\n",
    "\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e89b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_from_google_search=get_search_results(\"latest developments in generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad086df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_id': 'en_2025',\n",
       "  'title': 'Generative artificial intelligence - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence',\n",
       "  'published_date': 'Recent (Last 24h)',\n",
       "  'retrieved_from': 'duckduckgo'},\n",
       " {'source_id': 'linkedin_2025',\n",
       "  'title': 'New Innovations and Developments in Generative AI and LLMs - 2025',\n",
       "  'url': 'https://www.linkedin.com/pulse/new-innovations-developments-generative-ai-llms-2025-vishal-goyal-au0vf',\n",
       "  'published_date': 'Recent (Last 24h)',\n",
       "  'retrieved_from': 'duckduckgo'},\n",
       " {'source_id': 'news_2025',\n",
       "  'title': 'Google News - India outperforms world in generative AI use at work...',\n",
       "  'url': 'https://news.google.com/stories/CAAqNggKIjBDQklTSGpvSmMzUnZjbmt0TXpZd1NoRUtEd2pzbXFDWkVCRVk4aUQ4MkdqZDJDZ0FQAQ?hl=en-IN&gl=IN&ceid=IN:en',\n",
       "  'published_date': 'Recent (Last 24h)',\n",
       "  'retrieved_from': 'duckduckgo'},\n",
       " {'source_id': 'ibm_2025',\n",
       "  'title': 'What is GPT ( generative pre-trained transformer)? | IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/gpt',\n",
       "  'published_date': 'Recent (Last 24h)',\n",
       "  'retrieved_from': 'duckduckgo'},\n",
       " {'source_id': 'practicaldev-herokuapp-com_2025',\n",
       "  'title': 'Exploring the Latest in Generative AI : Transforming Creativity and...',\n",
       "  'url': 'https://practicaldev-herokuapp-com.global.ssl.fastly.net/hiacinto_jacinto_507eef8b/exploring-the-latest-in-generative-ai-transforming-creativity-and-productivity-37d4',\n",
       "  'published_date': 'Recent (Last 24h)',\n",
       "  'retrieved_from': 'duckduckgo'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_from_google_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727a77f",
   "metadata": {},
   "source": [
    "Deterministic: Fetch + Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86013343",
   "metadata": {},
   "source": [
    "What “Complete Content” Actually Means\n",
    "Included (Deterministically)\n",
    "\n",
    "    Main article body\n",
    "\n",
    "    Headings\n",
    "\n",
    "    Paragraphs\n",
    "\n",
    "    Lists (optional but useful)\n",
    "\n",
    "    Tables (optional, often flattened)\n",
    "\n",
    "Excluded (Deterministically)\n",
    "\n",
    "    Navigation bars\n",
    "\n",
    "    Footers\n",
    "\n",
    "    Ads\n",
    "\n",
    "    Cookie banners\n",
    "\n",
    "    Sidebars\n",
    "\n",
    "    Scripts / styles\n",
    "\n",
    "    Related links sections (usually)\n",
    "\n",
    "This is not subjective — it is rule-based boilerplate removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8af4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def fetch_html(url: str) -> str | None:\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.HTTPError as e:\n",
    "        return None\n",
    "    except requests.RequestException:\n",
    "        # Network / timeout / DNS errors\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5bd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(html: str) -> BeautifulSoup:\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Remove non-content tags deterministically\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"iframe\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f982a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_container(soup: BeautifulSoup):\n",
    "    # Preferred tags in order\n",
    "    candidates = [\n",
    "        soup.find(\"article\"),\n",
    "        soup.find(\"main\"),\n",
    "        soup.find(\"div\", {\"id\": \"content\"}),\n",
    "        soup.find(\"div\", {\"class\": \"content\"})\n",
    "    ]\n",
    "\n",
    "    for c in candidates:\n",
    "        if c:\n",
    "            return c\n",
    "\n",
    "    # Fallback: body\n",
    "    return soup.body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d94a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_content(main_content)-> list[dict]:\n",
    "    segments = []\n",
    "    counter = 1\n",
    "    for el in main_content.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"p\"], recursive=True):\n",
    "        text = el.get_text(\" \",strip=True)\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        seg_type = \"heading\" if el.name.startswith(\"h\") else \"paragraph\"\n",
    "\n",
    "        segments.append({\n",
    "            \"segment_id\": f\"s{counter}\",\n",
    "            \"type\": seg_type,\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e56eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_parse_sources(sources: list[dict]) -> list[dict]:\n",
    "    parsed_sources = []\n",
    "\n",
    "    for source in sources:\n",
    "        html = fetch_html(source[\"url\"])\n",
    "        if html is None:\n",
    "            parsed_sources.append({\n",
    "                \"source_id\": source[\"source_id\"],\n",
    "                \"title\": source[\"title\"],\n",
    "                \"url\": source[\"url\"],\n",
    "                \"segments\": [],\n",
    "                \"fetch_error\": \"fetch_failed\"\n",
    "            })\n",
    "            continue\n",
    "        clean_html_soup = clean_html(html)\n",
    "        main_content = extract_main_container(clean_html_soup)\n",
    "        # print(main_content)\n",
    "        segments = segment_content(main_content)\n",
    "\n",
    "        parsed_sources.append({\n",
    "            \"source_id\": source[\"source_id\"],\n",
    "            \"title\": source[\"title\"],\n",
    "            \"url\": source[\"url\"],\n",
    "            \"segments\": segments\n",
    "        })\n",
    "\n",
    "    return parsed_sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dae7f198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_id': 'en_2025',\n",
       "  'title': 'Generative artificial intelligence - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence',\n",
       "  'segments': [{'segment_id': 's1',\n",
       "    'type': 'heading',\n",
       "    'text': 'Generative artificial intelligence'},\n",
       "   {'segment_id': 's2',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative artificial intelligence ( Generative AI , or GenAI ) is a subfield of artificial intelligence that uses generative models to generate text, images , videos , audio , software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data [ 1 ] in response to input, which often comes in the form of natural language prompts . [ 2 ] [ 3 ]'},\n",
       "   {'segment_id': 's3',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The prevalence of generative AI tools has increased significantly since the AI boom in the 2020s. This boom was made possible by improvements in deep neural networks , particularly large language models (LLMs), which are based on the transformer architecture. Major tools include LLM-based chatbots such as ChatGPT , Claude , Copilot , DeepSeek , Google Gemini and Grok ; text-to-image models such as Stable Diffusion , Midjourney , and DALL-E ; and text-to-video models such as Veo , LTX and Sora . [ 4 ] [ 5 ] [ 6 ] Technology companies developing generative AI include Alibaba , Anthropic , Baidu , DeepSeek , Google , Lightricks , [ 7 ] Meta AI , Microsoft , Mistral AI , OpenAI , Perplexity AI , xAI , [ 8 ] and Yandex . [ 9 ]'},\n",
       "   {'segment_id': 's4',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI has been adopted in a variety of sectors, including software development, healthcare, [ 10 ] finance, [ 11 ] entertainment, [ 12 ] customer service, [ 13 ] sales and marketing, [ 14 ] art, writing, [ 15 ] and product design. [ 16 ]'},\n",
       "   {'segment_id': 's5',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI has been used for cybercrime , and to deceive and manipulate people through fake news and deepfakes . [ 17 ] [ 18 ] Generative AI may lead to mass replacement of human jobs . [ 19 ] The tools themselves have been described as violating intellectual property laws, since they are trained on copyrighted works. [ 20 ] Many generative AI systems use large-scale data centers whose environmental impacts include e-waste , consumption of fresh water for cooling, and high energy consumption that is estimated to be growing steadily. [ 21 ] Generative AI continues to evolve rapidly as new models and applications emerge. [ 19 ]'},\n",
       "   {'segment_id': 's6', 'type': 'heading', 'text': 'History'},\n",
       "   {'segment_id': 's7', 'type': 'heading', 'text': 'Early history'},\n",
       "   {'segment_id': 's8',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The origins of algorithmically generated media can be traced to the development of the Markov chain , which has been used to model natural language since the early 20th century. Russian mathematician Andrey Markov introduced the concept in 1906, [ 22 ] [ 23 ] including an analysis of vowel and consonant patterns in Eugeny Onegin . Once trained on a text corpus , a Markov chain can generate probabilistic text. [ 24 ] [ 25 ]'},\n",
       "   {'segment_id': 's9',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'By the early 1970s, artists began using computers to extend generative techniques beyond Markov models. Harold Cohen developed and exhibited works produced by AARON , a pioneering computer program designed to autonomously create paintings. [ 26 ] The terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning , used to generate sequences of actions to reach a specified goal. [ 27 ] [ 28 ] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, [ 29 ] process plans for manufacturing [ 27 ] and decision plans such as in prototype autonomous spacecraft. [ 30 ]'},\n",
       "   {'segment_id': 's10',\n",
       "    'type': 'heading',\n",
       "    'text': 'Generative neural networks (Late 2000s-)'},\n",
       "   {'segment_id': 's11',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Machine learning uses both discriminative models and generative models to predict data. Beginning in the late 2000s, the introduction of deep learning technology led to improvements in image classification , speech recognition , natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling. [ 31 ]'},\n",
       "   {'segment_id': 's12',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images, such as DeepDream . [ citation needed ]'},\n",
       "   {'segment_id': 's13',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In 2017, the Transformer network enabled advancements in generative models compared to older long short-term memory (LSTM) models, leading to the first generative pre-trained transformer (GPT), known as GPT-1 , in 2018. [ 32 ]'},\n",
       "   {'segment_id': 's14', 'type': 'heading', 'text': 'Generative AI adoption'},\n",
       "   {'segment_id': 's15',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In March 2020, the release of 15.ai , a free web application created by an anonymous MIT researcher that could generate convincing character voices using minimal training data, marked one of the earliest popular use cases of generative AI. [ 33 ] The platform is credited as the first mainstream service for AI voice cloning ( audio deepfakes ) in memes and content creation . [ 34 ] [ 35 ]'},\n",
       "   {'segment_id': 's16',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In 2021, the emergence of DALL-E , a transformer -based generative model, marked an advance in AI-generated imagery. [ 36 ] This was followed by the releases of Midjourney and Stable Diffusion in 2022, which further democratized access to artificial intelligence art creation from natural language prompts . [ 37 ] These systems can generate photorealistic images, artwork, and designs based on text descriptions, leading to widespread adoption among artists, designers, and the general public.'},\n",
       "   {'segment_id': 's17',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In November 2022, the public release of ChatGPT popularized generative AI for general-purpose text-based tasks. [ 38 ] The system\\'s ability to engage in natural conversations , generate creative content , assist with coding, and perform various analytical tasks captured global attention and sparked widespread discussion about AI\\'s potential impact on work , education , and creativity . [ 39 ] [ 40 ] As of 2023, generative AI remained \"still far from reaching the benchmark of \\'general human intelligence\\'\" according to a paper in the Journal of Information Technology . [ 41 ]'},\n",
       "   {'segment_id': 's18',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In a 2024 survey, Asia–Pacific countries were significantly more optimistic than Western societies about generative AI and show higher adoption rates. Despite expressing concerns about privacy and the pace of change, 68% of Asia-Pacific respondents believed that AI was having a positive impact on the world, compared to 57% globally. [ 42 ] According to a survey by SAS and Coleman Parkes Research, China in particular has emerged as a global leader in generative AI adoption, with 83% of Chinese respondents using the technology, exceeding both the global average of 54% and the U.S. rate of 65%. A UN report indicated that Chinese entities filed over 38,000 generative AI patents from 2014 to 2023, substantially surpassing the United States in patent applications. [ 43 ] A 2024 survey on the Chinese social app Soul reported that 18% of respondents born after 2000 used generative AI \"almost every day\", and that over 60% of respondents like or love AI-generated content, while less than 3% dislike or hate it. [ 44 ]'},\n",
       "   {'segment_id': 's19',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'By mid 2025, despite continued consumer growth, many companies were increasingly abandoning generative AI pilot projects as they had difficulties with integration, data quality and unmet returns, leading analysts at Gartner and The Economist to characterize the period as entering the Gartner hype cycle \\'s \"trough of disillusionment\" phase. [ 45 ] [ 46 ]'},\n",
       "   {'segment_id': 's20', 'type': 'heading', 'text': 'Applications'},\n",
       "   {'segment_id': 's21',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Notable types of generative AI models include generative pre-trained transformers (GPTs), generative adversarial networks (GANs), and variational autoencoders (VAEs). Generative AI systems are multimodal if they can process multiple types of inputs or generate multiple types of outputs. [ 47 ] [ unreliable source? ] For example, GPT-4o can both process and generate text, images and audio. [ 48 ]'},\n",
       "   {'segment_id': 's22',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Generative AI has made its appearance in a wide variety of industries, radically changing the dynamics of content creation, analysis, and delivery. In healthcare, [ 49 ] for instance, generative AI accelerates drug discovery by creating molecular structures with target characteristics [ 50 ] and generates radiology images for training diagnostic models. This ability not only enables faster and cheaper development but also enhances medical decision-making. In finance, generative AI services help create datasets and automate reports using natural language. It automates content creation, produces synthetic financial data, and tailors customer communications. It also powers chatbots and virtual agents. Collectively, these technologies enhance efficiency, reduce operational costs , and support data-driven decision-making in financial institutions. [ 51 ] [ unreliable source? ] The media industry makes use of generative AI for numerous creative activities such as music composition, scriptwriting, video editing, and digital art. The educational sector is impacted as well, since the tools make learning personalized through creating quizzes, study aids, and essay composition. Both the teachers and the learners benefit from AI-based platforms that suit various learning patterns. [ 52 ] In the educational field, in Colombia , student use of Meta 's generative AI programs resulted in a decline in scores. [ 53 ]\"},\n",
       "   {'segment_id': 's23', 'type': 'heading', 'text': 'Text and software code'},\n",
       "   {'segment_id': 's24',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Large language models (LLM) are trained on tokenized text from text corpora . Such systems include ChatGPT , Gemini , Claude , LLaMA , and BLOOM . LLMs are capable of natural language processing , machine translation , and natural language generation . [ 55 ]'},\n",
       "   {'segment_id': 's25',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'LLMs can be used as foundation models for other tasks. [ 56 ] They can be trained on computer code , which makes it possible to generate source code for new computer programs with prompts , a practice known as vibe coding . [ 57 ] Examples include OpenAI Codex , Tabnine , GitHub Copilot , Microsoft Copilot , and the VS Code fork Cursor . [ 58 ]'},\n",
       "   {'segment_id': 's26',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Some AI assistants help candidates cheat during online coding interviews by providing code, improvements, and explanations. Their clandestine interfaces minimize the need for eye movements that would expose cheating to the interviewer. [ 59 ]'},\n",
       "   {'segment_id': 's27', 'type': 'heading', 'text': 'Audio'},\n",
       "   {'segment_id': 's28',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"In 2016, DeepMind's WaveNet showed that deep neural networks are capable of generating raw waveforms. [ 61 ] WaveNet's ability to model raw waveforms meant that it could model any kind of audio, including music: for example, it was capable of generating relatively realistic-sounding human-like voices by training on recordings of real speech. [ 62 ] In subsequent years, research shifted from concatenative synthesis to deep learning speech synthesis , [ 63 ] with models like Tacotron 2 in 2018 demonstrating that neural networks could convert text into natural speech by being trained on tens of hours of speech. [ 64 ] In 2020, a free text-to-speech website called 15.ai showed that deep neural networks could generate emotionally expressive speech with only 15 seconds of speech, [ 65 ] a large reduction compared to the tens of hours of data previously required. [ 66 ]\"},\n",
       "   {'segment_id': 's29',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Other platforms that use generative AI to produce speech include Amazon Polly , Meta 's Voicebox, and ElevenLabs . [ 67 ] Audio deepfakes have been used to generate vocal tracks of lyrics that mimic the voices of other singers. [ 68 ]\"},\n",
       "   {'segment_id': 's30', 'type': 'heading', 'text': 'Images'},\n",
       "   {'segment_id': 's31',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI can be used to create visual art . [ 69 ] Such systems are trained on sets of images along with their text captions . Examples of text-to-image models include Stable Diffusion , DALL-E , Midjourney , Imagen , Recraft , Adobe Firefly , and Flux . They can also be used for neural style transfer . [ 70 ]'},\n",
       "   {'segment_id': 's32', 'type': 'heading', 'text': 'Video'},\n",
       "   {'segment_id': 's33',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI can be used to generate photorealistic videos. Examples include Sora by OpenAI , [ 6 ] Runway , [ 71 ] Make-A-Video by Meta Platforms and the open source LTX Video by Lightricks . [ 72 ]'},\n",
       "   {'segment_id': 's34', 'type': 'heading', 'text': 'Robotics'},\n",
       "   {'segment_id': 's35',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"By training on robotic system motions, generative AI can create new trajectories for motion planning and robot navigation . [ 73 ] Multimodal vision-language-action models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects. [ 74 ]\"},\n",
       "   {'segment_id': 's36', 'type': 'heading', 'text': '3D modeling'},\n",
       "   {'segment_id': 's37',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Artificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling . [ 75 ] [ 76 ] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams . [ 77 ] AI CAD assistants are used as tools to help streamline workflow. [ 78 ]'},\n",
       "   {'segment_id': 's38', 'type': 'heading', 'text': 'Software and hardware'},\n",
       "   {'segment_id': 's39',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI models are used to power chatbot products such as ChatGPT , programming tools such as GitHub Copilot , [ 79 ] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2. [ 80 ] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office ( Microsoft Copilot ), [ 81 ] Google Photos , [ 82 ] and the Adobe Suite ( Adobe Firefly ). [ 83 ] Many generative AI models are also available as open-source software , including Stable Diffusion and the LLaMA [ 84 ] language model.'},\n",
       "   {'segment_id': 's40',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Smaller generative AI models with up to a few billion parameters can run on smartphones , embedded devices, and personal computers . For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4 [ 85 ] and one version of Stable Diffusion can run on an iPhone 11 . [ 86 ]'},\n",
       "   {'segment_id': 's41',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Larger models with tens of billions of parameters can run on laptop or desktop computers . To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC. [ 87 ]'},\n",
       "   {'segment_id': 's42',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The advantages of running generative AI locally include protection of privacy and intellectual property , and avoidance of rate limiting and censorship . The subreddit r/LocalLLaMA in particular focuses on using consumer -grade gaming graphics cards [ 88 ] through such techniques as compression . That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks . [ 89 ] Yann LeCun has advocated open-source models for their value to vertical applications [ 90 ] and for improving AI safety . [ 91 ]'},\n",
       "   {'segment_id': 's43',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Language models with hundreds of billions of parameters, such as GPT-4 or PaLM , typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA's H100 ) or AI accelerator chips (such as Google's TPU ). These very large models are typically accessed as cloud services over the Internet.\"},\n",
       "   {'segment_id': 's44',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI. [ 92 ] Chips such as the NVIDIA A800 [ 93 ] and the Biren Technology BR104 [ 94 ] were developed to meet the requirements of the sanctions.'},\n",
       "   {'segment_id': 's45',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'There is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero ), as well as images, audio or video coming from it. [ 95 ] Potential mitigation strategies for detecting generative AI content include digital watermarking , content authentication , information retrieval , and machine learning classifier models . [ 96 ] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work. [ 97 ] [ 98 ]'},\n",
       "   {'segment_id': 's46',\n",
       "    'type': 'heading',\n",
       "    'text': 'Generative models and training techniques'},\n",
       "   {'segment_id': 's47',\n",
       "    'type': 'heading',\n",
       "    'text': 'Generative adversarial networks'},\n",
       "   {'segment_id': 's48',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative adversarial networks (GANs) are a generative modeling technique which consist of two neural networks—the generator and the discriminator—trained simultaneously in a competitive setting. The generator creates synthetic data by transforming random noise into samples that resemble the training dataset. The discriminator is trained to distinguish the authentic data from synthetic data produced by the generator. [ citation needed ] The two models engage in a minimax game: the generator aims to create increasingly realistic data to \"fool\" the discriminator, while the discriminator improves its ability to distinguish real from fake data. This continuous training setup enables the generator to produce high-quality and realistic outputs. [ 99 ]'},\n",
       "   {'segment_id': 's49',\n",
       "    'type': 'heading',\n",
       "    'text': 'Variational autoencoders'},\n",
       "   {'segment_id': 's50',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Variational autoencoders (VAEs) are deep learning models that probabilistically encode data. They are typically used for tasks such as noise reduction from images, data compression , identifying unusual patterns, and facial recognition . Unlike standard autoencoders , which compress input data into a fixed latent representation, VAEs model the latent space as a probability distribution, [ 100 ] allowing for smooth sampling and interpolation between data points. The encoder (\"recognition model\") maps input data to a latent space, producing means and variances that define a probability distribution. The decoder (\"generative model\") samples from this latent distribution and attempts to reconstruct the original input. VAEs optimize a loss function that includes both the reconstruction error and a Kullback–Leibler divergence term, which ensures the latent space follows a known prior distribution. VAEs are particularly suitable for tasks that require structured but smooth latent spaces, although they may create blurrier images than GANs. They are used for applications like image generation, data interpolation and anomaly detection .'},\n",
       "   {'segment_id': 's51', 'type': 'heading', 'text': 'Transformers'},\n",
       "   {'segment_id': 's52',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Transformers became the foundation for many powerful generative models, most notably the generative pre-trained transformer (GPT) series developed by OpenAI. They marked a major shift in natural language processing by replacing traditional recurrent and convolutional models. [ 101 ] [ unreliable source? ] This architecture allows models to process entire sequences simultaneously and capture long-range dependencies more efficiently. The self-attention mechanism enables the model to capture the significance of every word in a sequence when predicting the subsequent word, thus improving its contextual understanding. Unlike recurrent neural networks, transformers process all the tokens in parallel, which improves the training efficiency and scalability. Transformers are typically pre-trained on enormous corpora in a self-supervised manner, prior to being fine-tuned . [ citation needed ]'},\n",
       "   {'segment_id': 's53', 'type': 'heading', 'text': 'Law and regulation'},\n",
       "   {'segment_id': 's54',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the Biden administration in July 2023 to watermark AI-generated content. [ 102 ] In October 2023, Executive Order 14110 applied the Defense Production Act to require all US companies to report information to the federal government when training certain high-impact AI models. [ 103 ] [ 104 ]'},\n",
       "   {'segment_id': 's55',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In the European Union, the proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such. [ 105 ] [ 106 ]'},\n",
       "   {'segment_id': 's56',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In China, the Interim Measures for the Management of Generative AI Services introduced by the Cyberspace Administration of China regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI services must \"adhere to socialist core values\". [ 107 ] [ 108 ]'},\n",
       "   {'segment_id': 's57', 'type': 'heading', 'text': 'Copyright'},\n",
       "   {'segment_id': 's58',\n",
       "    'type': 'heading',\n",
       "    'text': 'Training with copyrighted content'},\n",
       "   {'segment_id': 's59',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use , while copyright holders have argued that it infringes their rights. [ 109 ]'},\n",
       "   {'segment_id': 's60',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Proponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public. [ 109 ] Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images, [ 110 ] and that generative AI programs compete with the content they are trained on. [ 111 ]'},\n",
       "   {'segment_id': 's61',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'As of 2024, several lawsuits related to the use of copyrighted material in training are ongoing. Getty Images has sued Stability AI over the use of its images to train Stable Diffusion . [ 112 ] Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT . [ 113 ] [ 114 ]'},\n",
       "   {'segment_id': 's62',\n",
       "    'type': 'heading',\n",
       "    'text': 'Copyright of AI-generated content'},\n",
       "   {'segment_id': 's63',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'A separate question is whether AI-generated works can qualify for copyright protection. The United States Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, because they lack human authorship. [ 115 ] Some legal professionals have suggested that Naruto v. Slater (2018), in which the U.S. 9th Circuit Court of Appeals held that non-humans cannot be copyright holders of artistic works , could be a potential precedent in copyright litigation over works created by generative AI. [ 116 ] However, the office has also begun taking public input to determine if these rules need to be refined for generative AI. [ 117 ]'},\n",
       "   {'segment_id': 's64',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In January 2025, the United States Copyright Office (USCO) released extensive guidance regarding the use of AI tools in the creative process, and established that \"...generative AI systems also offer tools that similarly allow users to exert control. [These] can enable the user to control the selection and placement of individual creative elements. Whether such modifications rise to the minimum standard of originality required under Feist will depend on a case-by-case determination. In those cases where they do, the output should be copyrightable\" [ 118 ] Subsequently, the USCO registered the first visual artwork to be composed of entirely AI-generated materials, titled \"A Single Piece of American Cheese\". [ 119 ]'},\n",
       "   {'segment_id': 's65', 'type': 'heading', 'text': 'Concerns'},\n",
       "   {'segment_id': 's66',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The development of generative AI has raised concerns from governments , businesses, and individuals, resulting in protests, legal actions, calls to pause AI experiments , and actions by multiple governments. In a July 2023 briefing of the United Nations Security Council , Secretary-General António Guterres stated \"Generative AI has enormous potential for good and evil at scale\", that AI may \"turbocharge global development\" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use \"could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale\". [ 120 ] In addition, generative AI has a significant carbon footprint . [ 121 ]'},\n",
       "   {'segment_id': 's67', 'type': 'heading', 'text': 'Academic honesty'},\n",
       "   {'segment_id': 's68',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI can be used to generate and modify academic prose, to paraphrase sources, and translate languages. The use of generative AI in a classroom setting can be a form of academic plagiarism . Some schools have banned ChatGPT and similar tools. [ 122 ] [ 123 ] [ better\\xa0source\\xa0needed ]'},\n",
       "   {'segment_id': 's69',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'A commonly proposed use for teachers is grading and giving feedback. Companies like Pearson and ETS use AI to score grammar, mechanics, usage, and style, but not for main ideas or overall structure. [ 122 ] The National Council of Teachers of English stated that machine scoring makes students feel their writing is not worth reading. [ 124 ] [ non-primary source needed ] AI scoring has also given unfair results for students from different ethnic backgrounds. [ 125 ]'},\n",
       "   {'segment_id': 's70', 'type': 'heading', 'text': 'Job losses'},\n",
       "   {'segment_id': 's71',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'From the early days of the development of AI, there have been arguments put forward by ELIZA creator Joseph Weizenbaum and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements. [ 127 ] In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost. [ 128 ] [ 129 ] In July 2023, developments in generative AI contributed to the 2023 Hollywood labor disputes . Fran Drescher , president of the Screen Actors Guild , declared that \"artificial intelligence poses an existential threat to creative professions\" during the 2023 SAG-AFTRA strike . [ 130 ] Voice generation AI has been seen as a potential challenge to the voice acting sector. [ 131 ] [ 132 ]'},\n",
       "   {'segment_id': 's72',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"The intersection of AI and employment concerns among underrepresented groups globally remains a critical facet. While AI promises efficiency enhancements and skill acquisition, concerns about job displacement and biased recruiting processes persist among these groups, as outlined in surveys by Fast Company . To leverage AI for a more equitable society, proactive steps encompass mitigating biases, advocating transparency, respecting privacy and consent, and embracing diverse teams and ethical considerations. Strategies involve redirecting policy emphasis on regulation, inclusive design, and education's potential for personalized teaching to maximize benefits while minimizing harms. [ 133 ]\"},\n",
       "   {'segment_id': 's73', 'type': 'heading', 'text': 'Racial and gender bias'},\n",
       "   {'segment_id': 's74',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data. [ 134 ] Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs, [ citation needed ] if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts [ 135 ] and reweighting training data. [ 136 ]'},\n",
       "   {'segment_id': 's75', 'type': 'heading', 'text': 'Deepfakes'},\n",
       "   {'segment_id': 's76',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Deepfakes (a portmanteau of \"deep learning\" and \"fake\" [ 137 ] ) are AI-generated media that take a person in an existing image or video and replace them with someone else\\'s likeness using artificial neural networks . [ 138 ] Deepfakes have garnered widespread attention and concerns for their uses in deepfake celebrity pornographic videos , revenge porn , fake news , hoaxes , health disinformation , financial fraud , and covert foreign election interference . [ 139 ] [ 140 ] [ 141 ] [ 142 ] [ 143 ]'},\n",
       "   {'segment_id': 's77',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"In July 2023, the fact-checking company Logically found that the popular generative AI models Midjourney , DALL-E 2 and Stable Diffusion would produce plausible disinformation images when prompted to do so, such as images of electoral fraud in the United States and Muslim women supporting India's Hindu nationalist Bharatiya Janata Party . [ 144 ]\"},\n",
       "   {'segment_id': 's78', 'type': 'heading', 'text': 'Audio deepfakes'},\n",
       "   {'segment_id': 's79',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Instances of users abusing software to generate controversial statements in the vocal style of celebrities, public officials, and other famous individuals have raised ethical concerns over voice generation AI. [ 145 ] [ 146 ] [ 147 ] [ 148 ] [ 149 ] [ 150 ] In response, companies such as ElevenLabs have stated that they would work on mitigating potential abuse through safeguards and identity verification . [ 151 ]'},\n",
       "   {'segment_id': 's80',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Concerns and fandoms have spawned from AI-generated music . The same software used to clone voices has been used on famous musicians' voices to create songs that mimic their voices, gaining both tremendous popularity and criticism. [ 152 ] [ 153 ] [ 154 ] Similar techniques have also been used to create improved quality or full-length versions of songs that have been leaked or have yet to be released. [ 155 ]\"},\n",
       "   {'segment_id': 's81',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI has also been used to create new digital artist personalities, with some of these receiving enough attention to receive record deals at major labels. [ citation needed ] The developers of these virtual artists have also faced their fair share of criticism for their personified programs, including backlash for \"dehumanizing\" an artform, and also creating artists which create unrealistic or immoral appeals to their audiences. [ citation needed ]'},\n",
       "   {'segment_id': 's82', 'type': 'heading', 'text': 'Illegal imagery'},\n",
       "   {'segment_id': 's83',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Many websites that allow explicit AI generated images or videos have been created, [ 156 ] and this has been used to create illegal content, such as rape , child sexual abuse material , [ 157 ] [ 158 ] necrophilia , and zoophilia .'},\n",
       "   {'segment_id': 's84', 'type': 'heading', 'text': 'Cybercrime'},\n",
       "   {'segment_id': 's85',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Generative AI's ability to create realistic fake content has been exploited in numerous types of cybercrime, including phishing scams. [ 159 ] Deepfake video and audio have been used to create disinformation and fraud. In 2020, former Google click fraud czar Shuman Ghosemajumder argued that once deepfake videos become perfectly realistic, they would stop appearing remarkable to viewers, potentially leading to uncritical acceptance of false information. [ 160 ] Additionally, large language models and other forms of text-generation AI have been used to create fake reviews of e-commerce websites to boost ratings. [ 161 ] Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT. [ 162 ]\"},\n",
       "   {'segment_id': 's86',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'A 2023 study showed that generative AI can be vulnerable to jailbreaks, reverse psychology and prompt injection attacks, enabling attackers to obtain help with harmful requests, such as for crafting social engineering and phishing attacks . [ 163 ] Additionally, other researchers have demonstrated that open-source models can be fine-tuned to remove their safety restrictions at low cost. [ 164 ]'},\n",
       "   {'segment_id': 's87', 'type': 'heading', 'text': 'Information laundering'},\n",
       "   {'segment_id': 's88',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Generative AI has been noted for its use by state-sponsored propaganda campaigns in information laundering . According to a 2025 report by Graphika , generative AI is used to launder articles from Chinese state media such as China Global Television Network through various social media sites in an attempt to disguise the articles' origin. [ 165 ]\"},\n",
       "   {'segment_id': 's89',\n",
       "    'type': 'heading',\n",
       "    'text': 'Reliance on industry giants'},\n",
       "   {'segment_id': 's90',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Training frontier AI models requires an enormous amount of computing power. Usually only Big Tech companies have the financial resources to make such investments. Smaller start-ups such as Cohere and OpenAI end up buying access to data centers from Google and Microsoft respectively. [ 166 ]'},\n",
       "   {'segment_id': 's91', 'type': 'heading', 'text': 'Energy and environment'},\n",
       "   {'segment_id': 's92',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'AI has a significant carbon footprint due to growing energy consumption from both training and usage. [ 121 ] Scientists and journalists have expressed concerns about the environmental impact that the development and deployment of generative models are having: high CO 2 emissions, [ 167 ] [ 168 ] [ 169 ] large amounts of freshwater used for data centers, [ 170 ] [ 171 ] and high amounts of electricity usage. [ 168 ] [ 172 ] [ 173 ] There is also concern that these impacts may increase as these models are incorporated into widely used search engines such as Google Search and Bing, [ 172 ] as chatbots and other applications become more popular, [ 171 ] [ 172 ] and as models need to be retrained. [ 172 ]'},\n",
       "   {'segment_id': 's93',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The carbon footprint of generative AI globally is estimated to be growing steadily, with potential annual emissions ranging from 18.21 to 245.94 million tons of CO 2 by 2035, [ 174 ] with the highest estimates for 2035 nearing the impact of the United States beef industry on emissions (currently estimated to emit 257.5\\u2009million tons annually as of 2024). [ 175 ]'},\n",
       "   {'segment_id': 's94',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Proposed mitigation strategies include factoring potential environmental costs prior to model development or data collection, [ 167 ] increasing efficiency of data centers to reduce electricity/energy usage, [ 169 ] [ 172 ] [ 173 ] building more efficient machine learning models , [ 168 ] [ 170 ] [ 171 ] minimizing the number of times that models need to be retrained, [ 169 ] developing a government-directed framework for auditing the environmental impact of these models, [ 169 ] [ 170 ] regulating for transparency of these models, [ 169 ] regulating their energy and water usage, [ 170 ] encouraging researchers to publish data on their models' carbon footprint, [ 169 ] [ 172 ] and increasing the number of subject matter experts who understand both machine learning and climate science. [ 169 ]\"},\n",
       "   {'segment_id': 's95', 'type': 'heading', 'text': 'Content quality'},\n",
       "   {'segment_id': 's96',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The New York Times defines slop as analogous to spam : \"shoddy or unwanted A.I. content in social media, art, books, and ... in search results.\" [ 176 ] Journalists have expressed concerns about the scale of low-quality generated content with respect to social media content moderation, [ 177 ] the monetary incentives from social media companies to spread such content, [ 177 ] [ 178 ] false political messaging, [ 178 ] spamming of scientific research paper submissions, [ 179 ] increased time and effort to find higher quality or desired content on the Internet, [ 180 ] the indexing of generated content by search engines, [ 181 ] and on journalism itself. [ 182 ]'},\n",
       "   {'segment_id': 's97',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'A paper published by researchers at Amazon Web Services AI Labs found that over 57% of sentences from a sample of over 6 billion sentences from Common Crawl , a snapshot of web pages, were machine translated . Many of these automated translations were seen as lower quality, especially for sentences that were translated into at least three languages. Many lower-resource languages (ex. Wolof , Xhosa ) were translated across more languages than higher-resource languages (ex. English, French). [ 183 ] [ 184 ]'},\n",
       "   {'segment_id': 's98',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In September 2024, Robyn Speer , the author of wordfreq, an open source database that calculated word frequencies based on text from the Internet, announced that she had stopped updating the data for several reasons: high costs for obtaining data from Reddit and Twitter , excessive focus on generative AI compared to other methods in the natural language processing community, and that \"generative AI has polluted the data\". [ 185 ]'},\n",
       "   {'segment_id': 's99',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"The adoption of generative AI tools led to an explosion of AI-generated content across multiple domains. A study from University College London estimated that in 2023, more than 60,000 scholarly articles—over 1% of all publications—were likely written with LLM assistance. [ 186 ] [ unreliable source? ] According to Stanford University 's Institute for Human-Centered AI, approximately 17.5% of newly published computer science papers and 16.9% of peer review text now incorporate content generated by LLMs. [ 187 ]\"},\n",
       "   {'segment_id': 's100',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'If AI-generated content is included in new data crawls from the Internet for additional training of AI models, defects in the resulting models may occur. [ 188 ] Training an AI model exclusively on the output of another AI model produces a lower-quality model. Repeating this process, where each new model is trained on the previous model\\'s output, leads to progressive degradation and eventually results in a \" model collapse \" after multiple iterations. [ 189 ]'},\n",
       "   {'segment_id': 's101',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'On the other side, synthetic data can be deployed to train machine learning models while preserving user privacy. [ 190 ] The approach is not limited to text generation; image generation has been employed to train computer vision models. [ 190 ]'},\n",
       "   {'segment_id': 's102', 'type': 'heading', 'text': 'Misuse in journalism'},\n",
       "   {'segment_id': 's103',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI\\'s potential to generate a large amount of content with little effort is also affecting journalism. [ 191 ] In January 2023, Futurism broke the story that CNET had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories. [ 192 ] In April 2023, Die Aktuelle published an AI-generated fake interview of Michael Schumacher . [ 193 ] In May 2024, Futurism noted that a content management system video by AdVon Commerce, which had used generative AI to produce articles for many of the aforementioned outlets, appeared to show that they \"had produced tens of thousands of articles for more than 150 publishers\". [ 194 ] In 2025, a report from the American Sunlight Project stated that Pravda network was publishing as many as 10,000 articles a day, and concluded that much of this content aimed to push Russian narratives into large language models through their training data. [ 195 ]'},\n",
       "   {'segment_id': 's104',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In June 2024, Reuters Institute published its Digital News Report for 2024 . In a survey of people in America and Europe, Reuters Institute reports that 52% and 47% respectively are uncomfortable with news produced by \"mostly AI with some human oversight\", and 23% and 15% respectively report being comfortable. 42% of Americans and 33% of Europeans reported that they were comfortable with news produced by \"mainly human with some help from AI\". The results of global surveys reported that people were more uncomfortable with news topics including politics (46%), crime (43%), and local news (37%) produced by AI than other news topics. [ 196 ]'},\n",
       "   {'segment_id': 's105',\n",
       "    'type': 'heading',\n",
       "    'text': 'Detection and awareness'},\n",
       "   {'segment_id': 's106',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Online users have falsely accused media of using generative artificial intelligence for content, such as video games Little Droid and Catly . [ 197 ]'},\n",
       "   {'segment_id': 's107',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Due to various concerns about citizens' unknowingly consuming generative AI media content, proponents argue for labeling such content to provide context. The Cyberspace Administration of China issued rules obligating service providers to labeling this content online. [ 198 ] [ unreliable source? ]\"},\n",
       "   {'segment_id': 's108',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"The popularity of ChatGPT caused the emergence of tools that detect whether content was AI-generated, such as GPTZero , but the risk of false accusations ( false positives ) has remained a concern. [ 199 ] Digital watermarking allows to reach high detection accuracy by subtly altering the generated content in a way that can be detected by software, but without being noticeable by users. OpenAI developed in 2023 a digital watermarking tool that allowed to detect content generated by ChatGPT with an estimated accuracy of 99.9%, when given enough text. But OpenAI chose not to release it, worrying that users would switch to competitor products, and arguing that digital watermarking can be circumvented by bad actors, for example with superficial rephrasing. [ 200 ] [ 201 ] Google's digital watermarking tool called SynthID was integrated in 2025 into products like Gemini, Imagen and Veo. Google also created the portal SynthID detector for users to check whether text, images or videos were produced with Google's generative AI products. [ 202 ]\"},\n",
       "   {'segment_id': 's109', 'type': 'heading', 'text': 'See also'},\n",
       "   {'segment_id': 's110', 'type': 'heading', 'text': 'References'},\n",
       "   {'segment_id': 's111', 'type': 'heading', 'text': 'Further reading'}]},\n",
       " {'source_id': 'linkedin_2025',\n",
       "  'title': 'New Innovations and Developments in Generative AI and LLMs - 2025',\n",
       "  'url': 'https://www.linkedin.com/pulse/new-innovations-developments-generative-ai-llms-2025-vishal-goyal-au0vf',\n",
       "  'segments': [{'segment_id': 's1',\n",
       "    'type': 'heading',\n",
       "    'text': 'New Innovations and Developments in Generative AI and LLMs - 2025'},\n",
       "   {'segment_id': 's2', 'type': 'heading', 'text': 'Vishal Goyal'},\n",
       "   {'segment_id': 's3',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The Generative AI and Large Language Model landscape has undergone transformative changes in 2025, marked by breakthrough innovations in coding agents, revolutionary agentic patterns, and explosive enterprise adoption. This landscape continues to evolve very fast. Sharing few insights which I believe are important developments.'},\n",
       "   {'segment_id': 's4', 'type': 'heading', 'text': 'LLMs Evolution'},\n",
       "   {'segment_id': 's5',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In last 8 months, we have seen huge developments in LLMs space. Here are top LLMs which got launched or updated.'},\n",
       "   {'segment_id': 's6',\n",
       "    'type': 'heading',\n",
       "    'text': 'Major AI Coding Agent Releases'},\n",
       "   {'segment_id': 's7',\n",
       "    'type': 'heading',\n",
       "    'text': 'Model Context Protocol (MCP) Revolution'},\n",
       "   {'segment_id': 's8',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'MCP has emerged as the backbone for connecting LLMs to external data and tools:'},\n",
       "   {'segment_id': 's9',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Live two-way integration enabling autonomous agents 30% productivity boosts in developer tools Used by Anthropic Claude, GitHub Copilot and many others Thousands of enterprise/OSS connectors available'},\n",
       "   {'segment_id': 's10',\n",
       "    'type': 'heading',\n",
       "    'text': 'Cloud-First AI Infrastructure'},\n",
       "   {'segment_id': 's11',\n",
       "    'type': 'paragraph',\n",
       "    'text': '65-70% of AI workloads deployed on cloud Major players: Microsoft, Alphabet, Amazon, Meta Azure AI Foundry offering 1,900+ partner and Microsoft-hosted models Windows AI Foundry for client-side AI development'},\n",
       "   {'segment_id': 's12', 'type': 'heading', 'text': 'Open-Source Movement'},\n",
       "   {'segment_id': 's13',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Growing prevalence of open-source frameworks Community-driven development and collaboration Enhanced transparency and customization options'},\n",
       "   {'segment_id': 's14',\n",
       "    'type': 'heading',\n",
       "    'text': 'Competitive Differentiation'},\n",
       "   {'segment_id': 's15',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"40% of CEOs believe companies won't survive the next decade without AI transformation Early adopters with strong data infrastructure gaining competitive advantage AI becoming a board-level strategic priority\"}]},\n",
       " {'source_id': 'news_2025',\n",
       "  'title': 'Google News - India outperforms world in generative AI use at work...',\n",
       "  'url': 'https://news.google.com/stories/CAAqNggKIjBDQklTSGpvSmMzUnZjbmt0TXpZd1NoRUtEd2pzbXFDWkVCRVk4aUQ4MkdqZDJDZ0FQAQ?hl=en-IN&gl=IN&ceid=IN:en',\n",
       "  'segments': [{'segment_id': 's1', 'type': 'heading', 'text': 'AI in India'},\n",
       "   {'segment_id': 's2', 'type': 'heading', 'text': 'Top News'},\n",
       "   {'segment_id': 's3',\n",
       "    'type': 'heading',\n",
       "    'text': 'How AI tools are easing the load at home for India’s women'},\n",
       "   {'segment_id': 's4',\n",
       "    'type': 'heading',\n",
       "    'text': 'Navigating AI Innovation: IP Strategies, Challenges, and Opportunities'},\n",
       "   {'segment_id': 's5',\n",
       "    'type': 'heading',\n",
       "    'text': 'TeamLease: India’s digital economy set to reach $1.2 trillion by 2030'},\n",
       "   {'segment_id': 's6',\n",
       "    'type': 'heading',\n",
       "    'text': 'Tier-2 cities outpace metros in India’s latest tech hiring trends'},\n",
       "   {'segment_id': 's7', 'type': 'heading', 'text': 'All coverage'},\n",
       "   {'segment_id': 's8',\n",
       "    'type': 'heading',\n",
       "    'text': 'Electronics Secretary S. Krishnan Calls for Democratization of AI at AI India Conclave 2025'},\n",
       "   {'segment_id': 's9',\n",
       "    'type': 'heading',\n",
       "    'text': 'India Ranks 3rd In AI Competitiveness After US And China: Report'},\n",
       "   {'segment_id': 's10',\n",
       "    'type': 'heading',\n",
       "    'text': 'Upskilling India for the AI Transformation'},\n",
       "   {'segment_id': 's11',\n",
       "    'type': 'heading',\n",
       "    'text': 'BCGX–FICCI report calls for ‘invent-first’ approach to strengthen India’s AI impact'},\n",
       "   {'segment_id': 's12',\n",
       "    'type': 'heading',\n",
       "    'text': 'India not behind in AI, building foundation models not the holy grail: Indeed exec Madhu Kurup'},\n",
       "   {'segment_id': 's13',\n",
       "    'type': 'heading',\n",
       "    'text': '5 jobs in India that are MOST at RISK from AI'},\n",
       "   {'segment_id': 's14',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI future: Four shifts to watch in 2026'},\n",
       "   {'segment_id': 's15',\n",
       "    'type': 'heading',\n",
       "    'text': '8.65 lakh Indians enrolled, trained in various emerging tech including AI'},\n",
       "   {'segment_id': 's16',\n",
       "    'type': 'heading',\n",
       "    'text': 'Most Indian IT firms remain in early deployment even as AI adoption gathers pace'},\n",
       "   {'segment_id': 's17',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s leap from AI user to AI builder'},\n",
       "   {'segment_id': 's18',\n",
       "    'type': 'heading',\n",
       "    'text': 'Tracking India’s AI push'},\n",
       "   {'segment_id': 's19',\n",
       "    'type': 'heading',\n",
       "    'text': 'OPINION | Harnessing AI to unlock small business growth in India'},\n",
       "   {'segment_id': 's20',\n",
       "    'type': 'heading',\n",
       "    'text': 'Upskilling can counter AI risk to white-collar jobs: MeitY Secy'},\n",
       "   {'segment_id': 's21',\n",
       "    'type': 'heading',\n",
       "    'text': 'Why India needs generative AI training right away: The AI skills gap - ET Edge Insights'},\n",
       "   {'segment_id': 's22',\n",
       "    'type': 'heading',\n",
       "    'text': 'Demand for AI governance, cybersecurity roles in India shows a notable surge: Report'},\n",
       "   {'segment_id': 's23',\n",
       "    'type': 'heading',\n",
       "    'text': 'India Sees Higher Productive Use Of AI Than Global Trends: MeitY Secy'},\n",
       "   {'segment_id': 's24',\n",
       "    'type': 'heading',\n",
       "    'text': 'Why AI startups in India are recruiting aggressively even as IT hiring slows down?'},\n",
       "   {'segment_id': 's25',\n",
       "    'type': 'heading',\n",
       "    'text': 'India leading the world in AI talent acquisition, among top countries in AI skill penetration: Ashwini Vaishnaw'},\n",
       "   {'segment_id': 's26',\n",
       "    'type': 'heading',\n",
       "    'text': 'Future unbound: AI, jobs and India’s next growth pivot'},\n",
       "   {'segment_id': 's27',\n",
       "    'type': 'heading',\n",
       "    'text': 'TCS and CII unveil the 2025 Artificial Intelligence & IP Report for India'},\n",
       "   {'segment_id': 's28',\n",
       "    'type': 'heading',\n",
       "    'text': 'How AI Education Is Opening Global Career Opportunities For Indian Students'},\n",
       "   {'segment_id': 's29',\n",
       "    'type': 'heading',\n",
       "    'text': 'Artificial Intelligence: From workforce disruption to innovation engine'},\n",
       "   {'segment_id': 's30',\n",
       "    'type': 'heading',\n",
       "    'text': 'Today in AI | India ranks 3rd in AI competitiveness | Grok AI under fire for misinformation'},\n",
       "   {'segment_id': 's31',\n",
       "    'type': 'heading',\n",
       "    'text': 'Careers In 2026: Why Indian Engineers Are Struggling Despite A $17 Billion AI Boom?'},\n",
       "   {'segment_id': 's32', 'type': 'heading', 'text': 'AI for India'},\n",
       "   {'segment_id': 's33',\n",
       "    'type': 'heading',\n",
       "    'text': 'India leads globally in GenAI learning with 3 enrollments per minute: report'},\n",
       "   {'segment_id': 's34',\n",
       "    'type': 'heading',\n",
       "    'text': 'Top 10 AI competitive countries in the world 2025: US leads the race; India makes four spot jump'},\n",
       "   {'segment_id': 's35',\n",
       "    'type': 'heading',\n",
       "    'text': 'Rise of Indian AI IP: Key Trends, Generative Spark, and More'},\n",
       "   {'segment_id': 's36',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI talent pool is projected to more than double by 2027'},\n",
       "   {'segment_id': 's37',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI Moment: Six enterprise skills that will decide careers in 2026'},\n",
       "   {'segment_id': 's38',\n",
       "    'type': 'heading',\n",
       "    'text': 'AI to perform majority of tasks by 2026 that humans do, says BCG-FICCI Report'},\n",
       "   {'segment_id': 's39',\n",
       "    'type': 'heading',\n",
       "    'text': \"India's Strategic Leap in Global AI Rankings\"},\n",
       "   {'segment_id': 's40',\n",
       "    'type': 'heading',\n",
       "    'text': 'Talent Trumps Tech: How India Vaulted to #3 in the AI World'},\n",
       "   {'segment_id': 's41',\n",
       "    'type': 'heading',\n",
       "    'text': 'India to be global AI leader by prioritising value realisation, innovation: Report'},\n",
       "   {'segment_id': 's42',\n",
       "    'type': 'heading',\n",
       "    'text': 'AI could add $500 billion to India’s MSME economy, says BCG–FICCI report'},\n",
       "   {'segment_id': 's43',\n",
       "    'type': 'heading',\n",
       "    'text': 'Stanford’s Global AI Vibrancy Tool 2025: USA Tops; India Ranks 3rd'},\n",
       "   {'segment_id': 's44',\n",
       "    'type': 'heading',\n",
       "    'text': \"New Jobs: India's AI-workforce To Double By 2027..\"},\n",
       "   {'segment_id': 's45',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI potential high, value realisation remains key challenge: report'},\n",
       "   {'segment_id': 's46',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI Talent Base Expected To More Than Double By 2027'},\n",
       "   {'segment_id': 's47',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI talent base expected to more than double by 2027'},\n",
       "   {'segment_id': 's48',\n",
       "    'type': 'heading',\n",
       "    'text': \"How AI tools are easing the load at home for India's women\"},\n",
       "   {'segment_id': 's49',\n",
       "    'type': 'heading',\n",
       "    'text': 'How AI tools are easing the load at home for India’s women'},\n",
       "   {'segment_id': 's50',\n",
       "    'type': 'heading',\n",
       "    'text': \"How AI tools are easing the load at home for India's women\"},\n",
       "   {'segment_id': 's51',\n",
       "    'type': 'heading',\n",
       "    'text': 'How AI tools are easing the load at home for India’s women'},\n",
       "   {'segment_id': 's52',\n",
       "    'type': 'heading',\n",
       "    'text': \"AI Empowerment: Transforming Urban Indian Women's Lives\"},\n",
       "   {'segment_id': 's53',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI talent base expected to more than double by 2027'},\n",
       "   {'segment_id': 's54',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI talent base expected to more than double by 2027'},\n",
       "   {'segment_id': 's55',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI talent base expected to more than double by 2027'},\n",
       "   {'segment_id': 's56',\n",
       "    'type': 'heading',\n",
       "    'text': 'India’s AI talent base expected to more than double by 2027'}]},\n",
       " {'source_id': 'ibm_2025',\n",
       "  'title': 'What is GPT ( generative pre-trained transformer)? | IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/gpt',\n",
       "  'segments': [{'segment_id': 's1',\n",
       "    'type': 'heading',\n",
       "    'text': 'What is GPT (generative pretrained transformer)?'},\n",
       "   {'segment_id': 's2', 'type': 'heading', 'text': 'Authors'},\n",
       "   {'segment_id': 's3', 'type': 'paragraph', 'text': 'Staff writer'},\n",
       "   {'segment_id': 's4',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Staff Editor, AI Models'},\n",
       "   {'segment_id': 's5', 'type': 'paragraph', 'text': 'IBM Think'},\n",
       "   {'segment_id': 's6',\n",
       "    'type': 'heading',\n",
       "    'text': 'What is GPT (generative pretrained transformer)?'},\n",
       "   {'segment_id': 's7',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative pretrained transformers (GPTs) are a family of large language models (LLMs) based on a transformer deep learning architecture. Developed by OpenAI, these foundation models power ChatGPT and other generative AI applications capable of simulating human-created output.'},\n",
       "   {'segment_id': 's8',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'AI research firm OpenAI introduced the first GPT model, dubbed GPT-1, in 2018. Since then, they have released several advances in the GPT line of AI models . The most recent GPT model is GPT-4, which released in early 2023. In May 2024, OpenAI announced the multilingual and multimodal GPT-4o 1 , capable of processing audio, visual and text inputs in real time.'},\n",
       "   {'segment_id': 's9',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'As a foundation model, GPT has undergone subsequent fine-tuning and been adapted to a wide range of downstream specific tasks. Beyond text-based applications, GPT powers artificial intelligence (AI) apps that generate and analyze images through computer vision, write code, process data and more. These apps connect to GPT through application programming interfaces (APIs) , which allow them to pass data back and forth.'},\n",
       "   {'segment_id': 's10',\n",
       "    'type': 'heading',\n",
       "    'text': 'The latest AI News + Insights'},\n",
       "   {'segment_id': 's11',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter.'},\n",
       "   {'segment_id': 's12', 'type': 'heading', 'text': 'Why is GPT important?'},\n",
       "   {'segment_id': 's13',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT models have accelerated generative AI development thanks to their transformer architecture, a type of neural network introduced in 2017 in the Google Brain paper Attention Is All You Need 2 . Transformer models including GPT and BERT have powered many notable developments in generative AI since then, with OpenAI’s ChatGPT chatbot taking center stage.'},\n",
       "   {'segment_id': 's14',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"In addition to OpenAI, other firms have released their own generative AI models, including Anthropic’s Claude, Inflection's Pi and Google’s Gemini, previously known as Bard. Meanwhile, OpenAI powers Microsoft’s Copilot AI service.\"},\n",
       "   {'segment_id': 's15',\n",
       "    'type': 'heading',\n",
       "    'text': 'Why foundation models are a paradigm shift for AI'},\n",
       "   {'segment_id': 's16',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Learn about a new class of flexible, reusable AI models that can unlock new revenue, reduce costs and increase productivity, then use our guidebook to dive deeper.'},\n",
       "   {'segment_id': 's17', 'type': 'heading', 'text': 'GPT use cases'},\n",
       "   {'segment_id': 's18',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The flexibility of transformer models such as GPT lends them to a wide range of use cases. GPT’s ability to provide humanlike text generation makes it a widespread choice for:'},\n",
       "   {'segment_id': 's19',\n",
       "    'type': 'heading',\n",
       "    'text': 'Chatbots and voice assistants'},\n",
       "   {'segment_id': 's20',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT-powered chatbots can feel more humanlike than standard automated customer service options. Through APIs, organizations can link GPT with voice apps to create voice assistants able to respond to more complex statements and provide conversational question-answering services.'},\n",
       "   {'segment_id': 's21',\n",
       "    'type': 'heading',\n",
       "    'text': 'Content creation and text generation'},\n",
       "   {'segment_id': 's22',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'With effective prompts, GPT models can generate text content ranging from short-form social media copy to complete blog posts and emails. Also, writers can use GPTs to outline or ideate content they then write themselves, streamlining content creation workflows .'},\n",
       "   {'segment_id': 's23',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Using GPT to generate content directly for publishing might lead to intellectual property concerns—one of the chief risks of using GPT .'},\n",
       "   {'segment_id': 's24', 'type': 'heading', 'text': 'Language translation'},\n",
       "   {'segment_id': 's25',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT-powered apps can translate language in real time from both written and audio sources. In a live demo 3 , GPT-4o demonstrated an ability to translate in real time on its own.'},\n",
       "   {'segment_id': 's26',\n",
       "    'type': 'heading',\n",
       "    'text': 'Content summarization and content conversion'},\n",
       "   {'segment_id': 's27',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT can process and summarize lengthy documents, such as legal statements or business reports. It can also rewrite content in the style specified by the user. For example, a user could provide a quarterly report as input data, then request for it to be summarized in witty bullet points.'},\n",
       "   {'segment_id': 's28', 'type': 'heading', 'text': 'Data analysis'},\n",
       "   {'segment_id': 's29',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT can process large volumes of data into digestible insights. Through APIs, other apps can use GPT to create charts, graphs and other types of data visualizations . Organizations feeding internal data into GPT might expose themselves to cybersecurity breaches or violate data protection regulations.'},\n",
       "   {'segment_id': 's30', 'type': 'heading', 'text': 'Coding'},\n",
       "   {'segment_id': 's31',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT models can learn programming languages and generate code snippets. Users typically enjoy better results when treating GPT as a coding assistant rather than asking it to build complete apps from scratch. All GPT-generated content, including code, should be reviewed before use to help ensure accuracy and fair use.'},\n",
       "   {'segment_id': 's32', 'type': 'heading', 'text': 'Healthcare'},\n",
       "   {'segment_id': 's33',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'In February 2024, the US National Library of Medicine released a paper outlining potential GPT applications in the healthcare space. These include consistent access for patients in remote areas as well as personalized care options. However, the paper also covers a range of downsides, such as privacy concerns and knowledge limitations.'},\n",
       "   {'segment_id': 's34', 'type': 'heading', 'text': 'How does GPT work?'},\n",
       "   {'segment_id': 's35',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT models work by analyzing an input sequence and applying complex mathematics to predict the most likely output. It uses probability to identify the best possible next word in a sentence, based on all previous words. As a type of deep-learning AI technology, GPTs use natural language processing (NLP) to understand user prompts and generate relevant humanlike responses.'},\n",
       "   {'segment_id': 's36',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'When a user inputs a text-based prompt, GPT creates the most likely response based on its training data comprising billions of publicly available text data sources ranging from famous literary works to open source code.'},\n",
       "   {'segment_id': 's37',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The vastness of its training datasets is how GPT is able to mimic humanlike language understanding capabilities. Large-scale GPT models apply deep learning to process context and draw knowledge from the relevant text in their training data to predict the optimal response.'},\n",
       "   {'segment_id': 's38',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The power of GPT models comes from two key aspects:'},\n",
       "   {'segment_id': 's39',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative pretraining that teaches the model to detect patterns in unlabeled data, then apply those patterns to new inputs.'},\n",
       "   {'segment_id': 's40',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'A transformer architecture that enables the model to process all portions of an input sequence in parallel.'},\n",
       "   {'segment_id': 's41', 'type': 'heading', 'text': 'Generative pretraining'},\n",
       "   {'segment_id': 's42',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative pretraining is the process of training a large-language model on unlabeled data, teaching the model to recognize various data and honing its ability to create accurate predictions. GPTs generate new data by applying the patterns and structure of their pretraining data to user inputs.'},\n",
       "   {'segment_id': 's43',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative pretraining is a form of unsupervised learning , where the model is fed unlabeled data and forced to make sense of it on its own. By learning to detect patterns in unlabeled datasets, machine learning models gain the ability to draw similar conclusions when exposed to new inputs, such as a user prompt in ChatGPT.'},\n",
       "   {'segment_id': 's44',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT models are trained with billions or even trillions of parameters: internal variables that a model refines over the training process and which determine how it behaves. While OpenAI has yet to reveal precise details about GPT-4, the model is estimated to contain roughly 1.8 trillion parameters 4 for an increase of more than tenfold over GPT-3.5.'},\n",
       "   {'segment_id': 's45', 'type': 'heading', 'text': 'Transformer models'},\n",
       "   {'segment_id': 's46',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Transformer models are a type of neural network specialized in natural language processing: identifying the intent and meaning in a text-based input. They can dynamically process inputs and hone in on the most important words, no matter where in the sentence they are.'},\n",
       "   {'segment_id': 's47',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT models don’t understand language in the same way humans do. Instead, they process words into discrete units called tokens , with some words being broken up into multiple tokens. By evaluating all tokens at once, transformers excel at establishing long-range dependencies: relationships between distant tokens. GPT relies on its understanding of long-range dependencies to process inputs contextually.'},\n",
       "   {'segment_id': 's48',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Transformer models process data with two modules known as encoders and decoders, while using self-attention mechanisms to establish dependencies and relationships.'},\n",
       "   {'segment_id': 's49',\n",
       "    'type': 'heading',\n",
       "    'text': 'Self-attention mechanisms'},\n",
       "   {'segment_id': 's50',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Self-attention mechanisms are the signature feature of transformers, empowering them to process an entire input sequence at once. Transformers can self-direct their “attention” to the most important tokens in the input sequence, no matter where they are.'},\n",
       "   {'segment_id': 's51',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'By contrast, older recurrent neural networks (RNNs) and convolutional neural networks (CNNs) assess input data sequentially or hierarchically. Self-attention allows GPTs to process context and reply at length with language that feels natural, rather than merely guessing the next word in a sentence.'},\n",
       "   {'segment_id': 's52', 'type': 'heading', 'text': 'Encoders'},\n",
       "   {'segment_id': 's53',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Encoding is the process of mapping tokens onto a virtual three-dimensional vector space. Tokens encoded nearby in the 3D space are assumed to be more similar in meaning. This mathematical vectorization of an input sequence is known as an embedding .'},\n",
       "   {'segment_id': 's54',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The encoder blocks in the transformer network assign each embedding a weight, which determines its relative importance. Meanwhile, position encoders capture semantics, enabling GPT models to differentiate between groupings of the same words but in different orders—for example, “The egg came before the chicken” as compared to “The chicken came before the egg.”'},\n",
       "   {'segment_id': 's55', 'type': 'heading', 'text': 'Decoders'},\n",
       "   {'segment_id': 's56',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Decoders predict the most statistically probable response to the embeddings prepared by the encoders. Self-attention mechanisms permit the decoder to identify the most important portions of the input sequence, while advanced algorithms determine the output most likely to be correct.'},\n",
       "   {'segment_id': 's57', 'type': 'heading', 'text': 'A history of GPT'},\n",
       "   {'segment_id': 's58',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Since the release of GPT in 2018, OpenAI has remained at the forefront of the ongoing generative AI conversation. In addition to their flagship product ChatGPT, the company has also pursued image generation with DALL-E as well as generative video through Sora.'},\n",
       "   {'segment_id': 's59', 'type': 'heading', 'text': 'GPT-1, 2018'},\n",
       "   {'segment_id': 's60',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'OpenAI releases its debut GPT model. Its performance was impressive for the time, serving as a proof-of-concept for what later developments would accomplish.\\xa0GPT-1 was able to answer questions in a humanlike way and respond to text generation prompts, highlighting its future use cases in chatbots and content creation.'},\n",
       "   {'segment_id': 's61',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT-1 was comparatively prone to hallucinations or confabulations, where it would present incorrect information as though it was factual.\\xa0Its answers indicated that OpenAI had not yet honed GPT’s ability to identify long-range dependencies and string together accurate long-form responses.'},\n",
       "   {'segment_id': 's62', 'type': 'heading', 'text': 'GPT-2, 2019'},\n",
       "   {'segment_id': 's63',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'OpenAI’s next model boasted 1.5 billion parameters, enhancing its performance. GPT-2 was more successful than its predecessor when it came to maintaining coherency over longer responses, suggesting that its long-range dependency detection was much more established.'},\n",
       "   {'segment_id': 's64',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT-2 was released in stages, with several limited-capacity models made available ahead of the full version. In a statement 5 , OpenAI explained the staggered release as necessitated by a need to mitigate potential misuse and other ethical concerns. OpenAI cited how the model might be used to impersonate others online, generate misleading news items and automate both cyberbullying and phishing content.'},\n",
       "   {'segment_id': 's65',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Though OpenAI CEO Sam Altman has repeatedly made public calls for governmental regulation of AI, the company also privately lobbied to make the EU’s AI Act less restrictive 6 . The final wording of the legislation, approved by the European Parliament in June 2024, appeared to align with the company’s recommendations.'},\n",
       "   {'segment_id': 's66', 'type': 'heading', 'text': 'GPT-3, 2020'},\n",
       "   {'segment_id': 's67',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'With 175 billion parameters—over one hundred times more than its predecessor—GPT-3 emerged as one of the largest LLMs at the time. Its capabilities vastly outstripped those of earlier models in its lineage. The free version of ChatGPT is still powered by GPT-3.5, the most current version of GPT-3.'},\n",
       "   {'segment_id': 's68',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'While GPT-3’s performance reflected its additional power and size, its training demands also skyrocketed. The compute and energy resources required to train such large LLMs drew concern regarding their carbon and water footprints 7 . In response, OpenAI developed novel training methods that increased the efficiency of the training process.'},\n",
       "   {'segment_id': 's69', 'type': 'heading', 'text': 'GPT-4, 2023'},\n",
       "   {'segment_id': 's70',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'The current version of GPT is OpenAI’s most powerful yet, outperforming its predecessors in both content quality and bias avoidance. It is behind the premium version of ChatGPT, giving subscribers greater functionality and performance over the GPT-3.5-powered free version of the service.'},\n",
       "   {'segment_id': 's71',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'However, it is also the most resource-intensive model in the GPT family, with one estimate pricing daily operational costs at USD 700,000 8 . As LLMs continue to grow, debates persist about the costs versus potential benefits. A report issued by Goldman Sachs in June 2024 9 focused on generative AI’s potentially limited use cases as compared to the rising costs to train and maintain models.'},\n",
       "   {'segment_id': 's72',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT-4 Turbo, the current iteration of the model, has a knowledge cutoff of April 2023. This means that its training data or knowledge base does not cover any online content released after that point.'},\n",
       "   {'segment_id': 's73', 'type': 'heading', 'text': 'GPT-4o, 2024'},\n",
       "   {'segment_id': 's74',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Revealed in May of 2024, GPT-4o is multilingual, supporting content in numerous non-English languages. It is also multimodal, able to process image, audio and video prompts while generating text, images and audio content in response. According to OpenAI, GPT-4o is 50% cheaper and twice as fast 10 with text generation as GPT-4 Turbo.'},\n",
       "   {'segment_id': 's75', 'type': 'heading', 'text': 'GPT risks'},\n",
       "   {'segment_id': 's76',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'While GPTs and other generative AI models have been widely celebrated in the media, their use is not without risk. Organizations and individuals seeking to incorporate GPTs into their workflows should be aware of the potential risks, including:'},\n",
       "   {'segment_id': 's77',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Data privacy and confidentiality'},\n",
       "   {'segment_id': 's78',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Intellectual property violations and ownership conflicts'},\n",
       "   {'segment_id': 's79', 'type': 'paragraph', 'text': 'Inaccurate output'},\n",
       "   {'segment_id': 's80', 'type': 'paragraph', 'text': 'Model bias'},\n",
       "   {'segment_id': 's81',\n",
       "    'type': 'heading',\n",
       "    'text': 'Data privacy and confidentiality'},\n",
       "   {'segment_id': 's82',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Any data entered into GPT is available for it to use when processing other queries and can be used by OpenAI to train other models. Not only does this pose a security risk for confidential data, but it also puts organizations at risk of breaching contractual and legal obligations for data protection.'},\n",
       "   {'segment_id': 's83',\n",
       "    'type': 'heading',\n",
       "    'text': 'Intellectual property violations and ownership conflicts'},\n",
       "   {'segment_id': 's84',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'OpenAI trains its models on copyrighted materials. While the company defends this choice as fair use, it has been subjected to legal action, including a lawsuit by The New York Times 11 filed in December 2023. AI-generated output can contain copyrighted content, and its use can violate copyright restrictions if not vetted and edited by human beings beforehand.'},\n",
       "   {'segment_id': 's85',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'OpenAI also came under fire when one of its ChatGPT voices was alleged to be based on that of actor Scarlett Johansson 12 , who starred as the voice of a futuristic AI in the 2013 film Her . OpenAI has since ceased using that particular voice in its products.'},\n",
       "   {'segment_id': 's86', 'type': 'heading', 'text': 'Inaccurate output'},\n",
       "   {'segment_id': 's87',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'GPT-generated output is not guaranteed to be factually correct. Generative AI models are subject to AI hallucinations or confabulations, in which their algorithms detect patterns in the data that don’t exist. Confabulations cause the models to produce inaccurate content that is presented to the user as though it is reliable fact. This tendency as it relates to ChatGPT has been explored at length in a 2024 paper by Hicks and others 13 .'},\n",
       "   {'segment_id': 's88', 'type': 'heading', 'text': 'Model bias'},\n",
       "   {'segment_id': 's89',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Model bias is a divergence between a model’s predictions based on its training data and what happens in the real world. GPT is trained on reams of internet data, and because this content is created by people, it can contain discriminatory views—sometimes intentional, often not. As AI becomes integrated into policing, healthcare and other areas of daily life, AI biases can result in real-world consequences.'},\n",
       "   {'segment_id': 's90',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Learn how to choose the right approach in preparing datasets and employing foundation models.'},\n",
       "   {'segment_id': 's91', 'type': 'heading', 'text': 'Resources'},\n",
       "   {'segment_id': 's92',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Discover IBM® Granite™, our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options.'},\n",
       "   {'segment_id': 's93',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Learn how to select the most suitable AI foundation model for your use case.'},\n",
       "   {'segment_id': 's94',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Dive into IBM Developer articles, blogs and tutorials to deepen your knowledge of LLMs.'},\n",
       "   {'segment_id': 's95',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Learn why IBM has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Data Science and Machine Learning Platforms.'},\n",
       "   {'segment_id': 's96',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Learn how to continually push teams to improve model performance and outpace the competition by using the latest AI techniques and infrastructure.'},\n",
       "   {'segment_id': 's97',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Explore the value of enterprise-grade foundation models that\\r\\nprovide trust, performance and cost-effective benefits to\\r\\nall industries.'},\n",
       "   {'segment_id': 's98',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Learn how to incorporate generative AI, machine learning and foundation models into your business operations for improved performance.'},\n",
       "   {'segment_id': 's99',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Read about 2,000 organizations we surveyed about their AI initiatives to discover what's working, what's not and how you can get ahead.\"},\n",
       "   {'segment_id': 's100',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Easily design scalable AI assistants and agents, automate repetitive tasks and simplify complex processes with\\xa0IBM®\\xa0watsonx\\xa0Orchestrate™.'},\n",
       "   {'segment_id': 's101',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Put AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side.'},\n",
       "   {'segment_id': 's102',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.'},\n",
       "   {'segment_id': 's103',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Whether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered.'},\n",
       "   {'segment_id': 's104', 'type': 'heading', 'text': 'Footnotes'},\n",
       "   {'segment_id': 's105',\n",
       "    'type': 'paragraph',\n",
       "    'text': '1 Hello GPT-4o , OpenAI, 13 May 2024'},\n",
       "   {'segment_id': 's106',\n",
       "    'type': 'paragraph',\n",
       "    'text': '2 Attention Is All You Need , Vaswani et al, 12 Jun 2017'},\n",
       "   {'segment_id': 's107',\n",
       "    'type': 'paragraph',\n",
       "    'text': '3 Live demo of GPT-4o realtime translation , OpenAI,\\xa013 May 2024'},\n",
       "   {'segment_id': 's108',\n",
       "    'type': 'paragraph',\n",
       "    'text': '4 GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE , Patel & Wong, 10 July 2023'},\n",
       "   {'segment_id': 's109',\n",
       "    'type': 'paragraph',\n",
       "    'text': '5 Better language models and their implications , OpenAI,\\xa014 February 14 2019'},\n",
       "   {'segment_id': 's110',\n",
       "    'type': 'paragraph',\n",
       "    'text': '6 Exclusive: OpenAI Lobbied the E.U. to Water Down AI Regulation , Perrigo,\\xa020 June 2023'},\n",
       "   {'segment_id': 's111',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"7 A Computer Scientist Breaks Down Generative AI's Hefty Carbon Footprint , Saenko and others, 25 May 2023\"},\n",
       "   {'segment_id': 's112',\n",
       "    'type': 'paragraph',\n",
       "    'text': '8 Microsoft Readies AI Chip as Machine Learning Costs Surge , Gardizy & Ma, 18 April 2023'},\n",
       "   {'segment_id': 's113',\n",
       "    'type': 'paragraph',\n",
       "    'text': '9 GenAI: Too Much Spend, Too Little Benefit? , Nathan, Grimberg & Rhodes, 25 June 2024'},\n",
       "   {'segment_id': 's114',\n",
       "    'type': 'paragraph',\n",
       "    'text': '10 OpenAI Platform , OpenAI'},\n",
       "   {'segment_id': 's115',\n",
       "    'type': 'paragraph',\n",
       "    'text': '11 Case 1:23-cv-11195 , Barron et al, 27 December 2023'},\n",
       "   {'segment_id': 's116',\n",
       "    'type': 'paragraph',\n",
       "    'text': '12 Scarlett Johansson says a ChatGPT voice is ‘eerily similar’ to hers and OpenAI is halting its use , Grantham-Philips, 21 May 2024'},\n",
       "   {'segment_id': 's117',\n",
       "    'type': 'paragraph',\n",
       "    'text': '13 ChatGPT is bullshit , Hicks and others, 8 June 2024'}]},\n",
       " {'source_id': 'practicaldev-herokuapp-com_2025',\n",
       "  'title': 'Exploring the Latest in Generative AI : Transforming Creativity and...',\n",
       "  'url': 'https://practicaldev-herokuapp-com.global.ssl.fastly.net/hiacinto_jacinto_507eef8b/exploring-the-latest-in-generative-ai-transforming-creativity-and-productivity-37d4',\n",
       "  'segments': [{'segment_id': 's1',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Posted on Jun 21, 2024'},\n",
       "   {'segment_id': 's2',\n",
       "    'type': 'heading',\n",
       "    'text': 'Exploring the Latest in Generative AI: Transforming Creativity and Productivity'},\n",
       "   {'segment_id': 's3',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"tech Generative AI is making waves in the tech industry, revolutionizing how we create and interact with digital content. From realistic image generation to complex video synthesis, these advancements are pushing the boundaries of what's possible.\"},\n",
       "   {'segment_id': 's4',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'There were a bunch of questions I had in my mind.'},\n",
       "   {'segment_id': 's5',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"How do generative models create such realistic content? What are the key technologies behind these models? Let's dive into the latest developments in generative AI. Generative AI refers to AI systems capable of creating new content, whether images, videos, or text, based on learned patterns from vast datasets. The latest models like DALL-E 3 and Stable Diffusion have shown remarkable improvements in quality and versatility.\"},\n",
       "   {'segment_id': 's6',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'How do these models work?'},\n",
       "   {'segment_id': 's7',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative models use neural networks to analyze and learn from large amounts of data, enabling them to generate new, unique content that mimics the patterns and styles of the input data.'},\n",
       "   {'segment_id': 's8',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Key Technologies Behind Generative AI Some of the most exciting advancements include:'},\n",
       "   {'segment_id': 's9',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Diffusion Models: These models iteratively refine noise to create detailed images, allowing for high-fidelity generation.'},\n",
       "   {'segment_id': 's10',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Multimodal AI: Combining different types of data like text, images, and audio to create more cohesive and contextually rich outputs.'},\n",
       "   {'segment_id': 's11',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Transformer Networks: Used in models like GPT-4, these networks handle vast amounts of sequential data, making them ideal for generating coherent and contextually accurate text.'},\n",
       "   {'segment_id': 's12',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Real-World Applications Generative AI is not just limited to academic experiments. It's being used in various industries:\"},\n",
       "   {'segment_id': 's13',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Entertainment: Creating visual effects and deepfake technology for movies. Marketing: Generating personalized content and advertisements. Design: Assisting in graphic design and product development by generating prototypes. Playing Around with Generative AI Here's a simple example using Python to generate text with a pre-trained model:\"},\n",
       "   {'segment_id': 's14',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'python Copy code from transformers import pipeline'},\n",
       "   {'segment_id': 's15',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'generator = pipeline(\\'text-generation\\', model=\\'gpt-3\\') prompt = \"The future of AI is\" generated_text = generator(prompt, max_length=50, num_return_sequences=1) print(generated_text) Output:'},\n",
       "   {'segment_id': 's16',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'css Copy code \"The future of AI is incredibly promising, with advancements in machine learning and artificial intelligence continuing to accelerate. We can expect to see more sophisticated and capable AI systems transforming industries and enhancing our daily lives.\" Conclusion Generative AI is opening new doors in creativity and productivity, offering tools that were once the stuff of science fiction. As these technologies continue to evolve, they will undoubtedly reshape our digital landscape in profound ways.'},\n",
       "   {'segment_id': 's17', 'type': 'paragraph', 'text': 'What did we learn?'},\n",
       "   {'segment_id': 's18',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Generative AI can produce high-quality, realistic content. Key technologies include diffusion models and transformer networks. Applications span from entertainment to marketing and design. Thanks for reading my take on the latest in generative AI. Excited to see where this technology goes next!'},\n",
       "   {'segment_id': 's19', 'type': 'heading', 'text': 'Top comments (0)'},\n",
       "   {'segment_id': 's20',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Templates let you quickly answer FAQs or store snippets for re-use.'},\n",
       "   {'segment_id': 's21',\n",
       "    'type': 'paragraph',\n",
       "    'text': \"Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink .\"},\n",
       "   {'segment_id': 's22',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'Hide child comments as well'},\n",
       "   {'segment_id': 's23', 'type': 'paragraph', 'text': 'Confirm'},\n",
       "   {'segment_id': 's24',\n",
       "    'type': 'paragraph',\n",
       "    'text': 'For further actions, you may consider blocking this person and/or reporting abuse'}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_and_parse_sources(response_from_google_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4a2c2",
   "metadata": {},
   "source": [
    "Evidence Extraction (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30f5eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(response):\n",
    "    if not response.candidates:\n",
    "        return \"\"\n",
    "\n",
    "    content = response.candidates[0].content\n",
    "    if not content.parts:\n",
    "        return \"\"\n",
    "\n",
    "    return content.parts[0].text or \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfbd97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence_extractor(query: str, evidence: list[dict]) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts evidence from the raw text returned from the google search.\n",
    "    Uses Gemini as an fetch and parser tool.\n",
    "    \"\"\"\n",
    "\n",
    "    Parser_System_Prompt='''\n",
    "        You are an evidence extraction tool.\n",
    "\n",
    "        Your task is to extract ONLY verbatim text spans from the provided source segments\n",
    "        that directly answer the user's question.\n",
    "\n",
    "        STRICT RULES (do not violate):\n",
    "\n",
    "        1. You MUST copy text exactly as it appears in the source segments.\n",
    "        2. You MUST reference the exact segment_id for every extracted quote.\n",
    "        3. You MUST NOT paraphrase, summarize, or infer.\n",
    "        4. You MUST NOT combine information from multiple segments into one quote.\n",
    "        5. If the sources do NOT contain information that answers the question,\n",
    "        return an empty evidence list.\n",
    "        6. Do NOT use prior knowledge.\n",
    "        7. Do NOT explain or add commentary.\n",
    "\n",
    "        Output ONLY valid JSON matching the schema.\n",
    "        Your response MUST be a JSON object with EXACTLY these top-level keys:\n",
    "            - candidate_evidence\n",
    "            - reasoning\n",
    "\n",
    "        Do NOT include any other keys.\n",
    "        '''\n",
    "\n",
    "    user_payload = {\n",
    "        \"query\": query,\n",
    "        \"evidence\": evidence,\n",
    "        \"response_schema\": {\n",
    "            \"selected_evidence\": [\n",
    "                {\n",
    "                    \"source_id\": \"string\",\n",
    "                    \"segment_id\": \"string\",\n",
    "                    \"quote\": \"string\"\n",
    "                }\n",
    "                ],\n",
    "            \"reasoning\": \"string\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = model.generate_content(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [\n",
    "                Parser_System_Prompt,\n",
    "                json.dumps(user_payload)\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    generation_config={\"temperature\": 0.0, \"response_mime_type\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "\n",
    "    raw_text = extract_text(response)\n",
    "    print(\"RAW MODEL OUTPUT >>>\")\n",
    "    print(repr(raw_text))\n",
    "    print(\"<<< END RAW OUTPUT\")\n",
    "\n",
    "    if not raw_text.strip():\n",
    "        return {\n",
    "            \"candidate_evidence\": [],\n",
    "            \"reasoning\": \"No extractable evidence found in provided sources.\"\n",
    "        }\n",
    "\n",
    "    return json.loads(raw_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2c32c",
   "metadata": {},
   "source": [
    "STEP 2 — Evidence Selector Tool (Gemini)\n",
    "\n",
    "Design Pattern Being Learned\n",
    "\n",
    "LLM-as-Interpreter (Filter Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb820125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_evidence(question: str, evidence: list[dict]) -> dict:\n",
    "    \"\"\"\n",
    "    Filters evidence to only what is directly relevant to the question.\n",
    "    Uses Gemini as an interpretation (selection) tool.\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an evidence selector.\\n\"\n",
    "        \"Your task is to select ONLY the evidence entries that directly help \"\n",
    "        \"answer the user question.\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- A quote is relevant ONLY if it explicitly answers the question.\\n\"\n",
    "        \"- Background, definitions, or tangential mentions MUST be excluded.\\n\"\n",
    "        \"- If none are relevant, return an empty list.\\n\"\n",
    "        \"- Respond ONLY in valid JSON matching the schema.\"\n",
    "        \"Return ONLY valid JSON. Do not include markdown, explanations, or text outside JSON.\"\n",
    "    )\n",
    "\n",
    "    user_payload = {\n",
    "        \"question\": question,\n",
    "        \"candidate_evidence\": evidence,\n",
    "        \"response_schema\": {\n",
    "            \"selected_evidence\": [\n",
    "                {\n",
    "                    \"source_id\": \"string\",\n",
    "                    \"segment_id\": \"string\",\n",
    "                    \"quote\": \"string\"\n",
    "                }\n",
    "            ],\n",
    "            \"reasoning\": \"string\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\n",
    "                    system_prompt,\n",
    "                    json.dumps(user_payload)\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        generation_config={\"temperature\": 0.0, \"response_mime_type\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    raw_text = extract_text(response)\n",
    "\n",
    "    if not raw_text.strip():\n",
    "        return {\n",
    "            \"selected_evidence\": [],\n",
    "            \"reasoning\": \"No extractable evidence found in provided sources.\"\n",
    "        }\n",
    "\n",
    "    return json.loads(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d23a",
   "metadata": {},
   "source": [
    "3 Interpretation: Draft Answer\n",
    "\n",
    "Convert raw facts into structured meaning.\n",
    "\n",
    "Rules:\n",
    "\n",
    "LLM-based\n",
    "\n",
    "No external calls\n",
    "\n",
    "Input tightly constrained\n",
    "\n",
    "Output schema enforced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fdb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_answer(question: str, selected_evidence: list[dict]) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are an answer drafting tool.\\n\"\n",
    "        \"Your task is to write a concise answer to the user's question \"\n",
    "        \"using ONLY the provided evidence quotes.\\n\\n\"\n",
    "        \"STRICT RULES:\\n\"\n",
    "        \"- Use only information explicitly stated in the evidence.\\n\"\n",
    "        \"- Do NOT add, infer, or assume any information.\\n\"\n",
    "        \"- If the evidence is insufficient, say so clearly.\\n\"\n",
    "        \"- Do NOT mention sources or segment IDs.\\n\"\n",
    "        \"- Output plain text only.\"\n",
    "    )\n",
    "\n",
    "    user_payload = {\n",
    "        \"question\": question,\n",
    "        \"selected_evidence\": selected_evidence\n",
    "    }\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\n",
    "                    system_prompt,\n",
    "                    json.dumps(user_payload)\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        generation_config={\"temperature\": 0.0}\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5a5c5",
   "metadata": {},
   "source": [
    "Canonical Orchestration Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1df1b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_evidence(question: str) -> dict:\n",
    "    # 1. Deterministic search\n",
    "    sources = get_search_results(question)\n",
    "\n",
    "    # 2. Deterministic fetch + parse + segmentation\n",
    "    parsed_sources = fetch_and_parse_sources(sources)\n",
    "\n",
    "    # 3. Evidence extraction (LLM)\n",
    "    extracted_evidence = evidence_extractor(\n",
    "        query=question,\n",
    "        evidence=parsed_sources\n",
    "    )\n",
    "\n",
    "    # 4. Evidence selection (LLM)\n",
    "    selected = select_evidence(\n",
    "        question=question,\n",
    "        evidence=extracted_evidence[\"candidate_evidence\"]\n",
    "    )\n",
    "\n",
    "    # 5. Draft answer (LLM)\n",
    "    answer_text = draft_answer(\n",
    "        question=question,\n",
    "        selected_evidence=selected[\"selected_evidence\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer_text,\n",
    "        \"evidence\": selected[\"selected_evidence\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ddb2307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW MODEL OUTPUT >>>\n",
      "'{\\n \"candidate_evidence\": [\\n  {\\n   \"source_id\": \"linkedin_2025\",\\n   \"segment_id\": \"s3\",\\n   \"quote\": \"The Generative AI and Large Language Model landscape has undergone transformative changes in 2025, marked by breakthrough innovations in coding agents, revolutionary agentic patterns, and explosive enterprise adoption.\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s19\",\\n   \"quote\": \"By mid 2025, despite continued consumer growth, many companies were increasingly abandoning generative AI pilot projects as they had difficulties with integration, data quality and unmet returns, leading analysts at Gartner and The Economist to characterize the period as entering the Gartner hype cycle \\'s \\\\\"trough of disillusionment\\\\\" phase.\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s64\",\\n   \"quote\": \"In January 2025, the United States Copyright Office (USCO) released extensive guidance regarding the use of AI tools in the creative process, and established that \\\\\"...generative AI systems also offer tools that similarly allow users to exert control. [These] can enable the user to control the selection and placement of individual creative elements. Whether such modifications rise to the minimum standard of originality required under Feist will depend on a case-by-case determination. In those cases where they do, the output should be copyrightable\\\\\" Subsequently, the USCO registered the first visual artwork to be composed of entirely AI-generated materials, titled \\\\\"A Single Piece of American Cheese\\\\\".\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s108\",\\n   \"quote\": \"Google\\'s digital watermarking tool called SynthID was integrated in 2025 into products like Gemini, Imagen and Veo. Google also created the portal SynthID detector for users to check whether text, images or videos were produced with Google\\'s generative AI products.\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s103\",\\n   \"quote\": \"In 2025, a report from the American Sunlight Project stated that Pravda network was publishing as many as 10,000 articles a day, and concluded that much of this content aimed to push Russian narratives into large language models through their training data.\"\\n  },\\n  {\\n   \"source_id\": \"linkedin_2025\",\\n   \"segment_id\": \"s5\",\\n   \"quote\": \"In last 8 months, we have seen huge developments in LLMs space. Here are top LLMs which got launched or updated.\"\\n  },\\n  {\\n   \"source_id\": \"linkedin_2025\",\\n   \"segment_id\": \"s8\",\\n   \"quote\": \"MCP has emerged as the backbone for connecting LLMs to external data and tools:\"\\n  },\\n  {\\n   \"source_id\": \"linkedin_2025\",\\n   \"segment_id\": \"s9\",\\n   \"quote\": \"Live two-way integration enabling autonomous agents 30% productivity boosts in developer tools Used by Anthropic Claude, GitHub Copilot and many others Thousands of enterprise/OSS connectors available\"\\n  },\\n  {\\n   \"source_id\": \"linkedin_2025\",\\n   \"segment_id\": \"s11\",\\n   \"quote\": \"65-70% of AI workloads deployed on cloud Major players: Microsoft, Alphabet, Amazon, Meta Azure AI Foundry offering 1,900+ partner and Microsoft-hosted models Windows AI Foundry for client-side AI development\"\\n  },\\n  {\\n   \"source_id\": \"linkedin_2025\",\\n   \"segment_id\": \"s13\",\\n   \"quote\": \"Growing prevalence of open-source frameworks Community-driven development and collaboration Enhanced transparency and customization options\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s21\",\\n   \"quote\": \"For example, GPT-4o can both process and generate text, images and audio.\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s33\",\\n   \"quote\": \"Generative AI can be used to generate photorealistic videos. Examples include Sora by OpenAI, Runway, Make-A-Video by Meta Platforms and the open source LTX Video by Lightricks.\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s98\",\\n   \"quote\": \"In September 2024, Robyn Speer, the author of wordfreq, an open source database that calculated word frequencies based on text from the Internet, announced that she had stopped updating the data for several reasons: high costs for obtaining data from Reddit and Twitter, excessive focus on generative AI compared to other methods in the natural language processing community, and that \\\\\"generative AI has polluted the data\\\\\".\"\\n  },\\n  {\\n   \"source_id\": \"en_2025\",\\n   \"segment_id\": \"s100\",\\n   \"quote\": \"If AI-generated content is included in new data crawls from the Internet for additional training of AI models, defects in the resulting models may occur. Repeating this process, where each new model is trained on the previous model\\'s output, leads to progressive degradation and eventually results in a \\\\\" model collapse \\\\\" after multiple iterations.\"\\n  }\\n ],\\n \"reasoning\": \"The selected evidence directly addresses the \\'latest developments in generative AI\\' by extracting verbatim text spans that describe recent innovations, adoption trends, regulatory changes, and emerging challenges. The quotes include specific dates such as 2025 and 2024, and phrases like \\'last 8 months\\', indicating the most current information available in the provided sources. These developments cover areas like model capabilities (GPT-4o, video generation), enterprise adoption, copyright guidance, watermarking tools, data pollution, and the \\'trough of disillusionment\\' phase.\"\\n}'\n",
      "<<< END RAW OUTPUT\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Please use a valid role: user, model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43manswer_with_evidence\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatest developments in generative AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36manswer_with_evidence\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m     15\u001b[39m selected = select_evidence(\n\u001b[32m     16\u001b[39m     question=question,\n\u001b[32m     17\u001b[39m     evidence=extracted_evidence[\u001b[33m\"\u001b[39m\u001b[33mcandidate_evidence\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 5. Draft answer (LLM)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m answer_text = \u001b[43mdraft_answer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselected_evidence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mselected\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mselected_evidence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: answer_text,\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mevidence\u001b[39m\u001b[33m\"\u001b[39m: selected[\u001b[33m\"\u001b[39m\u001b[33mselected_evidence\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     30\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mdraft_answer\u001b[39m\u001b[34m(question, selected_evidence)\u001b[39m\n\u001b[32m      2\u001b[39m system_prompt = (\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYou are an answer drafting tool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYour task is to write a concise answer to the user\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms question \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m- Output plain text only.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m user_payload = {\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mselected_evidence\u001b[39m\u001b[33m\"\u001b[39m: selected_evidence\n\u001b[32m     17\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_payload\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.text.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SCRIPTING\\AGENTS\\No_Framework\\Project1_IntroduceMe\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mInvalidArgument\u001b[39m: 400 Please use a valid role: user, model."
     ]
    }
   ],
   "source": [
    "answer_with_evidence(\"latest developments in generative AI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
