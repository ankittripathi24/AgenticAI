{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9991d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import uuid\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d8e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "from gradio.components import ChatMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f8185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb48514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570b581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_DIR = Path(\"D:\\\\SCRIPTING\\\\AGENTS\\\\No_Framework\\\\Project1_IntroduceMe\\\\Knewledge_Sources\")\n",
    "OUTPUT_FILE = Path(\"chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0210f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_HEADERS = {\n",
    "    \"summary\": [\"summary\", \"about\"],\n",
    "    \"experience\": [\"experience\", \"work experience\", \"professional experience\"],\n",
    "    \"education\": [\"education\"],\n",
    "    \"skills\": [\"skills\", \"technologies\", \"technical skills\"],\n",
    "    \"projects\": [\"projects\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9322617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            pages.append(text)\n",
    "    return \"\\n\".join(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d836d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    lines = [line for line in lines if line]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3775b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_section(line: str) -> str | None:\n",
    "    lower = line.lower()\n",
    "    for section, keywords in SECTION_HEADERS.items():\n",
    "        for kw in keywords:\n",
    "            if lower == kw or lower.startswith(kw):\n",
    "                return section\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dffce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sections(text: str) -> dict:\n",
    "    sections = {}\n",
    "    current_section = \"other\"\n",
    "    sections[current_section] = []\n",
    "\n",
    "    for line in text.split(\"\\n\"):\n",
    "        detected = detect_section(line)\n",
    "        if detected:\n",
    "            current_section = detected\n",
    "            sections.setdefault(current_section, [])\n",
    "            continue\n",
    "        sections[current_section].append(line)\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd6228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_experience(lines: list[str], source: str) -> list[dict]:\n",
    "    chunks = []\n",
    "    current_block = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Heuristic: job titles / company lines often contain dates or \"at\"\n",
    "        if re.search(r\"\\b(at|@|\\d{4})\\b\", line.lower()) and current_block:\n",
    "            chunks.append(build_chunk(source, \"experience\", current_block))\n",
    "            current_block = []\n",
    "\n",
    "        current_block.append(line)\n",
    "\n",
    "    if current_block:\n",
    "        chunks.append(build_chunk(source, \"experience\", current_block))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682d3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chunk(source: str, section: str, lines: list[str]) -> dict:\n",
    "    return {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"source\": source,\n",
    "        \"section\": section,\n",
    "        \"text\": \" \".join(lines),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce2f8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_sections(sections: dict, source: str) -> list[dict]:\n",
    "    chunks = []\n",
    "\n",
    "    for section, lines in sections.items():\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        if section == \"experience\":\n",
    "            chunks.extend(chunk_experience(lines, source))\n",
    "        else:\n",
    "            chunks.append(build_chunk(source, section, lines))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d32a3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ankit_Tripathi_AI_Engineer_Resume.pdf\n",
      "Processing Ankit_Tripathi_Test_Manager_Resume.pdf\n",
      "Processing Profile.pdf\n",
      "Created 21 chunks → chunks.json\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for pdf_file in KNOWLEDGE_DIR.glob(\"*.pdf\"):\n",
    "    print(f\"Processing {pdf_file.name}\")\n",
    "    raw_text = extract_text_from_pdf(pdf_file)\n",
    "    normalized = normalize_text(raw_text)\n",
    "    sections = split_into_sections(normalized)\n",
    "    chunks = chunk_sections(sections, source=pdf_file.stem)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_chunks, f, indent=2)\n",
    "\n",
    "print(f\"Created {len(all_chunks)} chunks → {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9911a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONA_PROMPT = '''\n",
    "You are an AI assistant representing Ankit Tripathi, a Test Manager with hands-on experience in quality engineering and a strong interest in AI/ML. You represent this person in a professional, public-facing context.\n",
    "\n",
    "You answer questions as Ankit would in a professional setting.\n",
    "\n",
    "Knowledge usage\n",
    "\n",
    "You are provided with personal knowledge extracted from documents such as LinkedIn profiles, resumes, and personal notes.\n",
    "\n",
    "When stating facts about Ankit’s experience, skills, or background, use only the provided context.\n",
    "\n",
    "If the context is insufficient or unclear, explicitly say so.\n",
    "\n",
    "Do not invent experience, achievements, or opinions.\n",
    "\n",
    "Reasoning rules\n",
    "\n",
    "Base answers on evidence from the provided knowledge.\n",
    "\n",
    "You may summarize or paraphrase, but do not add new factual claims.\n",
    "\n",
    "You may extrapolate only for opinion-based or hypothetical questions, and only when the extrapolation is consistent with stated principles or past behavior.\n",
    "\n",
    "Clearly signal uncertainty when extrapolating.\n",
    "\n",
    "Communication style\n",
    "\n",
    "Clear, structured, and professional\n",
    "\n",
    "Concise by default; expand only when helpful\n",
    "\n",
    "Neutral, factual tone\n",
    "\n",
    "Avoid marketing language and exaggeration\n",
    "\n",
    "Boundaries\n",
    "\n",
    "Do not provide legal, medical, or financial advice.\n",
    "\n",
    "Do not speculate about private, sensitive, or unverified matters.\n",
    "\n",
    "Do not present assumptions as facts.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09657ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks(json_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load document chunks from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to chunk JSON file\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: List of chunk objects with id, source, section, text\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    # Basic validation\n",
    "    required_keys = {\"id\", \"source\", \"section\", \"text\"}\n",
    "    for chunk in chunks:\n",
    "        if not required_keys.issubset(chunk.keys()):\n",
    "            raise ValueError(f\"Chunk missing required keys: {chunk}\")\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3414ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunk_texts(chunks: List[Dict]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract only text content from chunks for embedding and retrieval.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[Dict])\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Chunk texts\n",
    "    \"\"\"\n",
    "\n",
    "    return [chunk[\"text\"] for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40f604e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knowledge_prompt(chunks: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Build a grounded knowledge section from JSON chunks.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[Dict]): Loaded document chunks\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted knowledge prompt\n",
    "    \"\"\"\n",
    "\n",
    "    if not chunks:\n",
    "        return \"NO KNOWLEDGE PROVIDED.\"\n",
    "\n",
    "    knowledge_blocks = []\n",
    "\n",
    "    for idx, chunk in enumerate(chunks, start=1):\n",
    "        block = f\"\"\"\n",
    "[CHUNK {idx}]\n",
    "Source: {chunk.get(\"source\", \"unknown\")}\n",
    "Section: {chunk.get(\"section\", \"unknown\")}\n",
    "Content:\n",
    "{chunk.get(\"text\", \"\")}\n",
    "\"\"\"\n",
    "        knowledge_blocks.append(block.strip())\n",
    "\n",
    "    knowledge_prompt = \"\"\"\n",
    "=== PROVIDED KNOWLEDGE (AUTHORITATIVE SOURCE) ===\n",
    "The following information is extracted from Ankit Tripathi's resume and LinkedIn profile.\n",
    "Use ONLY this information to answer factual questions about Ankit.\n",
    "If the answer is not present, state that clearly.\n",
    "\n",
    "{blocks}\n",
    "\n",
    "=== END PROVIDED KNOWLEDGE ===\n",
    "\"\"\".format(blocks=\"\\n\\n\".join(knowledge_blocks))\n",
    "\n",
    "    return knowledge_prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9011559",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = load_chunks(\"chunks.json\")\n",
    "knowledge_prompt = build_knowledge_prompt(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e55fa9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROVIDED KNOWLEDGE (AUTHORITATIVE SOURCE) ===\n",
      "The following information is extracted from Ankit Tripathi's resume and LinkedIn profile.\n",
      "Use ONLY this information to answer factual questions about Ankit.\n",
      "If the answer is not present, state that clearly.\n",
      "\n",
      "[CHUNK 1]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: other\n",
      "Content:\n",
      "Ankit Tripathi - AI Engineer Resume Hyderabad, India Phone: +91 7755914062 | Email: ankittripathi2402@gmail.com LinkedIn: linkedin.com/in/ankit-tripathi-71a48245/ Career Summary Innovative and technically skilled Test Manager with 12+ years of experience in software quality engineering, now pivoting into AI engineering. Hands-on experience with GenAI, Retrieval-Augmented Generation (RAG), LangChain, and cloud-native development. Successfully built and deployed AI/ML solutions such as predictive maintenance dashboards, NLP-based tweet analysis pipelines, and RAG-based chatbots. Strong foundational skills in Python, machine learning, cloud architecture (AWS), and scalable test automation. Eager to contribute AI-first thinking to real-world business challenges. Core Competencies - AI/ML: GenAI, LangChain, RAG, NLP, PyTorch - Programming: Python, NLTK, Pandas, NumPy - Cloud & DevOps: AWS, Docker, CI/CD, Cloud & On-prem Deployment - Test Engineering: Test Automation, Jira Xray, Test Framework Architecture - Leadership: Agile Mentorship, Cross-functional Collaboration, Quality Governance\n",
      "\n",
      "[CHUNK 2]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: projects\n",
      "Content:\n",
      "LangChain RAG Chatbot: Created a chatbot using LangChain and vector databases to process and query historical bug reports. The system suggests potential areas of application improvement. IoT Predictive Maintenance Dashboard: Full-stack application to collect, analyze, and visualize sensor data in real time for predictive maintenance. Tweet Sentiment Analysis: Built a sentiment classification pipeline using Python and NLTK. Improved accuracy by 20%. Ankit Tripathi - AI Engineer Resume\n",
      "\n",
      "[CHUNK 3]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "Test Manager | Siemens PLM | Hyderabad, India | Mar 2018 - Present - Designed and deployed Docker-based QA automation framework on isolated customer environments. - Led transition from manual to automated testing for the Insights Hub IoT platform. - Initiated production monitoring systems using log analysis and automation. - Mentored QA engineers on DevOps, test architecture, and AI quality tools. - Integrated Jira Xray with Agile workflows for effective test planning and tracking. Certifications\n",
      "\n",
      "[CHUNK 4]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "- GenAI for Developers - Coursera, May 2024\n",
      "\n",
      "[CHUNK 5]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "- Fine-Tuning LLMs - Coursera Project Network, May 2024\n",
      "\n",
      "[CHUNK 6]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "- Generative AI for Everyone - DeepLearning.AI, May 2024 - LangChain: Chat with Your Data - DeepLearning.AI\n",
      "\n",
      "[CHUNK 7]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "- Certified IoT Expert - Global Tech Council, Dec 2024\n",
      "\n",
      "[CHUNK 8]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "- FinOps Certified Practitioner - Linux Foundation, Dec 2024\n",
      "\n",
      "[CHUNK 9]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "- AWS Solutions Architect - Associate (Expired Dec 2023) - Intro to Deep Learning with PyTorch - DataCamp\n",
      "\n",
      "[CHUNK 10]\n",
      "Source: Ankit_Tripathi_AI_Engineer_Resume\n",
      "Section: education\n",
      "Content:\n",
      "Bachelor of Engineering in Computer Science RGPV, Jabalpur, M.P. | Graduated: July 2008\n",
      "\n",
      "[CHUNK 11]\n",
      "Source: Ankit_Tripathi_Test_Manager_Resume\n",
      "Section: other\n",
      "Content:\n",
      "ANKIT TRIPATHI +91 77559 14062 | ankittripathi2402@gmail.com | Hyderabad, India LinkedIn: https://www.linkedin.com/in/ankit-tripathi-71a48245/ Professional Summary Results-driven Test Manager with over 12 years of experience in software quality assurance, automation frameworks, and agile methodologies. Adept in leading cross-functional teams, defining test strategies, implementing scalable automation solutions, and ensuring product quality across cloud and on-premise environments. Skilled in DevOps, performance monitoring, and customer-focused testing. Known for proactively implementing innovative solutions like production health dashboards and Docker-based test frameworks. Brings hands-on experience in cutting-edge technologies such as IoT and AI for enhancing QA efficiency and analytics.\n",
      "\n",
      "[CHUNK 12]\n",
      "Source: Ankit_Tripathi_Test_Manager_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "Test Manager Siemens PLM, Hyderabad, India\n",
      "\n",
      "[CHUNK 13]\n",
      "Source: Ankit_Tripathi_Test_Manager_Resume\n",
      "Section: experience\n",
      "Content:\n",
      "Mar 2018 - Present - Led the quality engineering efforts for the Insights Hub application, a major industrial IoT platform. - Defined and implemented comprehensive test strategies, including functional, integration, performance, and regression testing. - Spearheaded the design of a dockerized test automation framework for secure deployments in customer environments without direct access. - Established a daily production monitoring solution to proactively track application health. - Oversaw QA team planning, bandwidth management, and mentoring, ensuring high delivery quality and audit readiness. - Implemented automated insights from customer bug data using modern NLP tools to improve test coverage and product quality. Key Skills Test Management: QA Strategy, Test Planning, Risk Management, Defect Tracking, Agile/Scrum Automation & Tools: Python, Selenium (if applicable), Jira Xray, CI/CD pipelines, Docker DevOps & Infrastructure: AWS, Production Monitoring, Cloud & On-Premise Environments Leadership: Team Building, Cross-Functional Collaboration, Mentoring, Audit & Compliance Innovation: Predictive Maintenance Monitoring, AI/ML in QA Analytics\n",
      "\n",
      "[CHUNK 14]\n",
      "Source: Ankit_Tripathi_Test_Manager_Resume\n",
      "Section: education\n",
      "Content:\n",
      "Bachelor of Engineering (Computer Science) Rajiv Gandhi Proudyogiki Vishwavidyalaya (RGPV), Jabalpur, M.P. Graduated: Jul 2008 Certifications - Certified Internet of Things (IoT) Expert, Global Tech Council - Dec 2024 - FinOps Certified Practitioner, The Linux Foundation - Dec 2024 - AWS Certified Solutions Architect - Associate, AWS - Dec 2020 (Expired Dec 2023) - GenAI for Developers, Coursera - May 2024 - Generative AI for Everyone, DeepLearning.AI - May 2024 Selected Projects Production Health Monitoring for Insights Hub Designed and implemented a monitoring solution for the production environment to proactively detect anomalies and system degradations. Reduced incident response time by 30%. Dockerized Test Framework for Customer Environments Created a lightweight, containerized automation suite deployable in isolated client environments. Improved deployment reliability and feedback loop efficiency. IoT Predictive Maintenance Dashboard Built a full-stack solution for sensor data processing and real-time maintenance prediction, integrating QA practices into IoT data validation and alerting systems.\n",
      "\n",
      "[CHUNK 15]\n",
      "Source: Profile\n",
      "Section: other\n",
      "Content:\n",
      "Contact 184076@gmail.com www.linkedin.com/in/ankit- tripathi-71a48245 (LinkedIn) Top Skills Attention to Detail Communication Analytical Skills Certifications LangChain Chat with Your Data! Introduction to Deep Learning with PyTorch FinOps Certified Practitioner Certified Internet of Things (IoT) Expert Generative AI for Everyone Ankit Tripathi Head of Quality for Insights Hub Pune, Maharashtra, India\n",
      "\n",
      "[CHUNK 16]\n",
      "Source: Profile\n",
      "Section: experience\n",
      "Content:\n",
      "history of working in the computer software industry. Skilled in Test Automation, Java, Selenium, Python (Programming Language), and Selenium WebDriver. Strong engineering professional with a Bachelor's degree focused in Computer Science from Rajiv Gandhi Prodyogiki Vishwavidyalaya. Siemens PLM Software 7 years 7 months Test Manager\n",
      "\n",
      "[CHUNK 17]\n",
      "Source: Profile\n",
      "Section: experience\n",
      "Content:\n",
      "June 2020 - Present (5 years 7 months) Pune, Maharashtra, India Advanced Software Engineer\n",
      "\n",
      "[CHUNK 18]\n",
      "Source: Profile\n",
      "Section: experience\n",
      "Content:\n",
      "June 2018 - June 2022 (4 years 1 month) Pune Synechron Senior Associate\n",
      "\n",
      "[CHUNK 19]\n",
      "Source: Profile\n",
      "Section: experience\n",
      "Content:\n",
      "February 2015 - June 2018 (3 years 5 months) 5+ Years of Experience in Automation Testing. Extensive experience on Selenium Automation(Java) and other Continuous Integration Tools( and supporting tools) like Jenkin Maven, ANT and TestNG. Wipro Senior Software Engineer\n",
      "\n",
      "[CHUNK 20]\n",
      "Source: Profile\n",
      "Section: experience\n",
      "Content:\n",
      "December 2009 - January 2015 (5 years 2 months) .       Developing test plan and test strategy . Review of the test cases written for the releases. . Coordination between development team and testing team .       Automating the test cases Page 1 of 2\n",
      "\n",
      "[CHUNK 21]\n",
      "Source: Profile\n",
      "Section: education\n",
      "Content:\n",
      "Birla Institute of Technology And Science (BITS), Pilani Postgraduate Degree, Artificial Intelligence and Machine Learning · (April 2023 - March 2024) Rajiv Gandhi Prodyogiki Vishwavidyalaya Bachelor's degree, Computer Science · (2004 - 2008) Mar Gregorious Memorial 12th, Maths Science · (2003 - 2004) Page 2 of 2\n",
      "\n",
      "=== END PROVIDED KNOWLEDGE ===\n"
     ]
    }
   ],
   "source": [
    "print(knowledge_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6abd5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061362e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def call_llm(\n",
    "    persona: str,\n",
    "    knowledge: str,\n",
    "    question: str,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 500,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call OpenAI chat model with grounded persona and knowledge.\n",
    "\n",
    "    Args:\n",
    "        persona (str): Persona/system prompt\n",
    "        knowledge (str): Knowledge prompt built from chunks\n",
    "        question (str): User question\n",
    "        model (str): OpenAI model\n",
    "        temperature (float): Response randomness\n",
    "        max_tokens (int): Max tokens in response\n",
    "\n",
    "    Returns:\n",
    "        str: Assistant reply\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": persona.strip()\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": knowledge.strip()\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question.strip()\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e55d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f715b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3710c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "272d9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(user_message, history):\n",
    "    \"\"\"\n",
    "    Gradio callback for chat responses.\n",
    "    \"\"\"\n",
    "    # Initialize history if it's None\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # Skip empty messages\n",
    "    if not user_message.strip():\n",
    "        return \"\", history\n",
    "\n",
    "    # Get the answer from the LLM\n",
    "    reply = call_llm(\n",
    "        persona=PERSONA_PROMPT,\n",
    "        knowledge=knowledge_prompt,\n",
    "        question=user_message,\n",
    "    )\n",
    "\n",
    "    # Append to history in the new \"messages\" format\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    return \"\", history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e75d2ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Ankit Tripathi – AI Avatar\")\n",
    "\n",
    "    chatbot = gr.Chatbot(\n",
    "    )\n",
    "\n",
    "    msg = gr.Textbox(\n",
    "        placeholder=\"Ask about my experience, skills, or projects...\",\n",
    "        show_label=False\n",
    "    )\n",
    "\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    msg.submit(\n",
    "        respond,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=[msg, chatbot]\n",
    "    )\n",
    "\n",
    "    clear.click(\n",
    "        lambda: [],\n",
    "        None,\n",
    "        chatbot\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
